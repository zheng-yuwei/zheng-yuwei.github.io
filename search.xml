<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>AI算法工程师的思考</title>
      <link href="/2019/10/10/17_AI%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/"/>
      <url>/2019/10/10/17_AI%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>AI算法落地的一点粗浅思考。同时发现了一个很好的<a href="https://github.com/lonelygo/Shift-AI-models-to-real-world-products" target="_blank" rel="noopener">git库</a>。</p><a id="more"></a><h3 id="AI算法工程师应该具备的能力"><a href="#AI算法工程师应该具备的能力" class="headerlink" title="AI算法工程师应该具备的能力"></a>AI算法工程师应该具备的能力</h3><p>AI落地时大概要经过以下阶段：</p><ol><li>抽象与定义问题；</li><li>数据理解；</li><li>反思数据；</li><li>工程pipeline的建立；</li><li>回溯与迭代。</li></ol><h4 id="抽象与定义问题的能力"><a href="#抽象与定义问题的能力" class="headerlink" title="抽象与定义问题的能力"></a>抽象与定义问题的能力</h4><p>李航的《统计学习方法》中，定义了统计学习的三要素：模型（假设空间）、策略（评价准则）、算法（优化步骤）。描述了应用算法解决问题时的三个重要关键点。</p><p>作为的第一步，定义模型的假设空间，需要我们能从问题的实际描述之中，抽象与定义出适用于问题的模型。</p><p>其实这个能力作为传统算法或者数学建模、工程问题解决等领域，都是极其重要的。只不过当前的AI算法给人无所不能的假象，但又不赋予</p><p>在当前的AI实际应用中，问题的描述是比较高语义的智能应用场景，很多时候使用的是深度学习（不像统计学习、机器学习、概率统计等领域，具有强大的理论支撑），较难以理论分析不同的算法在最终应用效果上的差异（正向：问题到算法再到模型再到最终目标存在多种可能）；同时也难以从算法回头明确问题（反向：算法/模型回推问题归属领域）。所以，为了维护形成一个问题-&gt;实现-&gt;分析的优化迭代过程，必须不断的对问题进行抽象与定义。</p><p>而抽象与定义问题的过程，个人认为需要注意以下三点：</p><ol><li>目标场景；</li><li>问题边界/标准；</li><li>可能的建模方式。</li></ol><h4 id="理解数据"><a href="#理解数据" class="headerlink" title="理解数据"></a>理解数据</h4><p>相比rule-driven或theory-driven，更多的是data-driven，观察数据，从数据本身出发，与抽象与定义问题形成反馈，获得更多的有用信息。场景拆分、细化，问题转移（传感器、语言或视觉？）</p><h4 id="反思数据"><a href="#反思数据" class="headerlink" title="反思数据"></a>反思数据</h4><p>理解数据在于基于当前问题吃透给定的数据。但在实际项目落地中，不仅仅是接受给定数据，要反思数据：当前数据是否足够，是否可获取其他辅助数据？数据是否可标准，标注是否确切（半监督？弱标注？）</p><h4 id="工程pipeline的建立"><a href="#工程pipeline的建立" class="headerlink" title="工程pipeline的建立"></a>工程pipeline的建立</h4><p>利于快速迭代验证。</p><h4 id="回溯与迭代"><a href="#回溯与迭代" class="headerlink" title="回溯与迭代"></a>回溯与迭代</h4><p>进一步定义问题，思考与优化，时间、空间、准确率等指标的trade off。</p><h3 id="其他能力要求"><a href="#其他能力要求" class="headerlink" title="其他能力要求"></a>其他能力要求</h3><h4 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h4><p>思想的源泉，问题阻塞点解决的出路。</p><h4 id="分享与讨论"><a href="#分享与讨论" class="headerlink" title="分享与讨论"></a>分享与讨论</h4><p>社区、同事</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI算法工程师 </tag>
            
            <tag> 素养 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker安装Caffe</title>
      <link href="/2019/07/30/16_Docker%E5%AE%89%E8%A3%85Caffe/"/>
      <url>/2019/07/30/16_Docker%E5%AE%89%E8%A3%85Caffe/</url>
      
        <content type="html"><![CDATA[<p>先安装以下软件：<br><code>cuda</code>, <code>cudnn</code>, <code>openblas</code>, <code>protobuf</code>, <code>glog</code>, <code>gflags</code>, <code>hdf5</code>,<code>snappy</code>, <code>leveldb</code>, <code>boost(+python)</code>, <code>opencv(+python)</code>，<code>doxygen</code>，<code>lmdb</code>；</p><p>由于华为云提供包含cuda和cudnn的docker镜像，所以不用安装这两个。同时由于不能改变镜像中的<code>/usr</code>文件夹，所以最好不要通过apt安装以上依赖库。（华为云提供docker时的要求，否则用apt安装是最方便、最好的！！！）</p><a id="more"></a><h2 id="启动docker镜像"><a href="#启动docker镜像" class="headerlink" title="启动docker镜像"></a>启动docker镜像</h2><p>下载华为云docker镜像压缩包（<code>custom-gpu-cuda9-cudnn7-inner-moxing-cp36.tar</code>）后：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 加载镜像并重命名</span><br><span class="line">docker load -i 镜像压缩包文件名称</span><br><span class="line">docker images|grep dls</span><br><span class="line">docker tag #image-id basic-caffe:1.0.0</span><br><span class="line">docker images|grep dls</span><br><span class="line">docker rmi dls.io/eiwizard/custom-gpu-cuda9-inner-moxing-cp36:1.1</span><br><span class="line">docker images|grep basic-caffe</span><br></pre></td></tr></table></figure><p>建立文件夹software，用以放置安装包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 运行镜像，退出不关</span><br><span class="line">docker run --name test-basic-caffe -it #image-id bash</span><br><span class="line"># root@b0a4a7125b7f:/#</span><br><span class="line"># 其中 b0a4a7125b7f 为 container-id</span><br><span class="line"># 镜像里包含了cuda, cudnn, python3.6</span><br><span class="line">nvcc --version</span><br><span class="line">find / -name *cudnn*</span><br><span class="line">python --version</span><br><span class="line">Ctrl+P+Q</span><br><span class="line"># 查看运行容器，重新进入容器</span><br><span class="line">docker ps -a|grep test-basic-caffe</span><br><span class="line">docker attach #container-id</span><br><span class="line">cd /home</span><br><span class="line">mkdir software</span><br><span class="line">cd software</span><br><span class="line">Ctrl+P+Q</span><br></pre></td></tr></table></figure><p>docker退出及重新启动进入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker里#exit</span><br><span class="line">docker外#docker start -ia #container-id</span><br></pre></td></tr></table></figure><h2 id="安装caffe依赖库"><a href="#安装caffe依赖库" class="headerlink" title="安装caffe依赖库"></a>安装caffe依赖库</h2><p>1.下载并拷贝各个压缩包：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker cp boost_1_68_0.tar.gz b0a4a7125b7f:/home/software</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">docker attach #docker-id</span><br><span class="line">ls /home/software</span><br></pre></td></tr></table></figure><p>2.安装各个依赖库：</p><h3 id="安装zlib-libpng-jpegsrc-v9c："><a href="#安装zlib-libpng-jpegsrc-v9c：" class="headerlink" title="安装zlib, libpng, jpegsrc.v9c："></a>安装<code>zlib, libpng, jpegsrc.v9c</code>：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># zlib</span><br><span class="line">cd /home/software/zlib-1.2.11</span><br><span class="line">./configure --prefix=/home/software/zlib-1.2.11-install</span><br><span class="line">make -j &amp;&amp; make install</span><br><span class="line"># libpng</span><br><span class="line">export LDFLAGS=&quot;-L/home/software/zlib-1.2.11-install/lib&quot;</span><br><span class="line">export CPPFLAGS=&quot;-I/home/software/zlib-1.2.11-install/include&quot;</span><br><span class="line">cd /home/software/libpng-1.6.37</span><br><span class="line">./configure --prefix=/home/software/libpng-1.6.37-install</span><br><span class="line">make -j &amp;&amp; make install</span><br><span class="line"># jpeg-9c</span><br><span class="line">cd /home/software/jpeg-9c</span><br><span class="line">./configure --prefix=/home/software/jpeg-9c-install</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="安装cmake"><a href="#安装cmake" class="headerlink" title="安装cmake"></a>安装cmake</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/cmake-3.15.0-rc3</span><br><span class="line">./configure --system-curl --prefix=/home/software/cmake-3.15.0-rc3-install -- -DCMAKE_USE_OPENSSL=ON -DZLIB_LIBRARY=/home/software/zlib-1.2.11-install/lib/libz.so -DZLIB_INCLUDE_DIR=/home/software/zlib-1.2.11-install/include</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>在<code>/root</code>下的<code>vi .bashrc</code>中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/home/software/cmake-3.15.0-rc3-install/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/home/software/cmake-3.15.0-rc3-install/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><p>然后执行<code>source .bashrc &amp;&amp; cmake</code>。</p><h3 id="安装openblas"><a href="#安装openblas" class="headerlink" title="安装openblas"></a>安装openblas</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/OpenBLAS-0.3.6</span><br><span class="line">make CC=gcc FC=gfortran</span><br><span class="line">make PREFIX=/home/software/OpenBLAS-0.3.6-install install</span><br><span class="line">cd /home/software/OpenBLAS-0.3.6-install/lib</span><br><span class="line">ls</span><br></pre></td></tr></table></figure><h3 id="安装protobuf"><a href="#安装protobuf" class="headerlink" title="安装protobuf"></a>安装protobuf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/protobuf-2.6.1</span><br><span class="line">./configure --prefix=/home/software/protobuf-2.6.1-install</span><br><span class="line">make check</span><br><span class="line">make -j</span><br><span class="line">make install</span><br><span class="line">cd /home/software/protobuf-2.6.1-install/bin</span><br><span class="line">./protoc --version</span><br></pre></td></tr></table></figure><h3 id="安装snappy"><a href="#安装snappy" class="headerlink" title="安装snappy"></a>安装snappy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/snappy-1.1.7</span><br><span class="line">mkdir build</span><br><span class="line">cd build &amp;&amp; cmake -DCMAKE_INSTALL_PREFIX=/home/software/snappy-1.1.7-install ..</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="安装leveldb"><a href="#安装leveldb" class="headerlink" title="安装leveldb"></a>安装leveldb</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/leveldb-1.22</span><br><span class="line">mkdir -p build &amp;&amp; cd build</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/software/leveldb-1.22-install -DBUILD_SHARED_LIBS=ON ..</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="安装glog"><a href="#安装glog" class="headerlink" title="安装glog"></a>安装glog</h3><p>需要先安装<code>libtool</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/libtool-2.4.6</span><br><span class="line">./configure --prefix=/home/software/libtool-2.4.6-install</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>在<code>/root</code>下的<code>vi .bashrc</code>中添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export CMAKE_PATH=/home/software/cmake-3.15.0-rc3-install</span><br><span class="line">export LIBTOOL_PATH=/home/software/libtool-2.4.6-install</span><br><span class="line">export PATH=$LIBTOOL_PATH/bin:$CMAKE_PATH/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=$LIBTOOL_PATH/lib:$CMAKE_PATH/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><p>然后执行<code>source .bashrc &amp;&amp; cmake</code>以及<code>cp /home/software/libtool-2.4.6-install/share/aclocal/* /usr/share/aclocal/</code>（原因就是<code>aclocal</code>与<code>libtool</code>没有安装在一个相同目录下面，而<code>aclocal</code>是去默认安装目录 <code>/usr/share/aclocal</code> 下面搜索所有的<code>.m4</code>文件找所定义的宏，所以自定义安装后要copy到一起）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/glog-0.4.0</span><br><span class="line">aclocal -I m4</span><br><span class="line">./autogen.sh &amp;&amp; ./configure --prefix=/home/software/glog-0.4.0-install &amp;&amp; make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="安装gflags"><a href="#安装gflags" class="headerlink" title="安装gflags"></a>安装gflags</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/gflags-2.2.0</span><br><span class="line">mkdir build</span><br><span class="line">cd build/</span><br><span class="line">cmake -DCMAKE_INSTALL_PREFIX=/home/software/gflags-2.2.0-install -DBUILD_SHARED_LIBS=ON ..</span><br><span class="line">make -j</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h3 id="安装hdf5"><a href="#安装hdf5" class="headerlink" title="安装hdf5"></a>安装hdf5</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">（源码包下载太慢了）</span><br><span class="line">cd /home/software/hdf5-1.8.18</span><br><span class="line">./configure --prefix=/home/software/hdf5-1.8.18-install &amp;&amp; make -j &amp;&amp; make install</span><br><span class="line">或者</span><br><span class="line">conda install -c anaconda hdf5==1.8.18</span><br></pre></td></tr></table></figure><h3 id="安装boost-python"><a href="#安装boost-python" class="headerlink" title="安装boost(+python)"></a>安装boost(+python)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/boost_1_68_0</span><br><span class="line">vi tools/build/src/tools/python.jam</span><br></pre></td></tr></table></figure><p>修改其中547行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">includes ?= $(prefix)/include/python$(version) ; -&gt; includes ?= $(prefix)/include/python$(version)m ;</span><br></pre></td></tr></table></figure><p>然后指定python3路径及版本，安装<code>boost</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./bootstrap.sh --with-python=/root/miniconda3/bin/python --with-python-version=3.6 --with-python-root=/root/miniconda3 --prefix=/home/software/boost_1_68_0-install</span><br><span class="line">./b2 install -a --with=all</span><br><span class="line">./b2 --with-python --buildid=3</span><br></pre></td></tr></table></figure><p>建立软连接：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /home/software/boost_1_68_0-install/lib/libboost_python36.so.1.68.0 /home/software/boost_1_68_0-install/lib/libboost_python3.so</span><br></pre></td></tr></table></figure><h3 id="安装lmdb"><a href="#安装lmdb" class="headerlink" title="安装lmdb"></a>安装lmdb</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/lmdb-LMDB_0.9.23/libraries/liblmdb</span><br><span class="line">make -j</span><br><span class="line">mkdir -p /home/software/lmdb-LMDB_0.9.23-install/include</span><br><span class="line">mkdir -p /home/software/lmdb-LMDB_0.9.23-install/lib</span><br><span class="line">mkdir -p /home/software/lmdb-LMDB_0.9.23-install/bin</span><br><span class="line">for f in mdb_stat mdb_copy mdb_dump mdb_load; do cp $f /home/software/lmdb-LMDB_0.9.23-install/bin; done</span><br><span class="line">for f in liblmdb.a liblmdb.so; do cp $f /home/software/lmdb-LMDB_0.9.23-install/lib; done</span><br><span class="line">for f in lmdb.h; do cp $f /home/software/lmdb-LMDB_0.9.23-install/include; done</span><br></pre></td></tr></table></figure><h3 id="安装doxygen"><a href="#安装doxygen" class="headerlink" title="安装doxygen"></a>安装doxygen</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/doxygen-Release_1_8_15</span><br><span class="line">mkdir build &amp;&amp; cd build</span><br><span class="line">cmake -G &quot;Unix Makefiles&quot; -DCMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/home/software/doxygen-Release_1_8_15-install ..</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="安装opencv-contribu-python"><a href="#安装opencv-contribu-python" class="headerlink" title="安装opencv(+contribu+python)"></a>安装opencv(+contribu+python)</h3><p>由于<code>opencv</code>安装依赖<code>protobuf</code>，所以要找对应<code>opencv</code>安装版本的<code>protobuf</code>版本（我是<code>opencv-3.4.4</code>，对应<code>protobuf-3.5.1</code>），所以先conda安装（会升级Python版本）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge protobuf==3.5.1</span><br></pre></td></tr></table></figure><p>需要先下载<code>opencv</code>和<code>opencv-contrib</code>的包，解压然后按照：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">cd /home/software/opencv-3.4.4</span><br><span class="line">mkdir build &amp;&amp; cd build</span><br><span class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE -D BUILD_opencv_world=ON \</span><br><span class="line">      -D CMAKE_INSTALL_PREFIX=/home/software/opencv-3.4.4-install/ -D INSTALL_C_EXAMPLES=OFF \</span><br><span class="line">      -D OPENCV_EXTRA_MODULES_PATH=/home/software/opencv_contrib-3.4.4/modules \</span><br><span class="line">      -D OPENCV_ENABLE_NONFREE=ON -D BUILD_EXAMPLES=OFF -D WITH_FFMPEG=0 -D WITH_TIFF=OFF \</span><br><span class="line">      -D WITH_CUDA=ON -D ENABLE_FAST_MATH=1 -D CUDA_FAST_MATH=1 \</span><br><span class="line">      -D WITH_CUBLAS=ON -D WITH_LAPACK=OFF -D WITH_GTK=OFF -D WITH_GTK_2_X=OFF -D WITH_MATLAB=OFF -D WITH_QT=OFF \</span><br><span class="line">      -D CUDA_NVCC_FLAGS=&quot;-D_FORCE_INLINES&quot; -D ENABLE_CXX11=1 \</span><br><span class="line">      -D BUILD_opencv_python3=ON -D BUILD_opencv_python2=ON \</span><br><span class="line">      -D WITH_PROTOBUF=ON -D BUILD_PROTOBUF=OFF -D -BUILD_LIBPROTOBUF_FROM_SOURCES=OFF -D PROTOBUF_UPDATE_FILES=OFF \</span><br><span class="line">      -D ENABLE_PRECOMPILED_HEADERS=ON -D BLAS=Open \</span><br><span class="line">      -D Protobuf_INCLUDE_DIR=/home/software/protobuf-3.5.1-install/include \</span><br><span class="line">      -D Protobuf_INCLUDE_DIRS=/home/software/protobuf-3.5.1-install/include \</span><br><span class="line">      -D Protobuf_LIBRARIES=&apos;/home/software/protobuf-3.5.1-install/lib/libprotobuf.so;-lpthread&apos; \</span><br><span class="line">      -D Protobuf_LIBRARY=/home/software/protobuf-3.5.1-install/lib/libprotobuf.so \</span><br><span class="line">      -D Protobuf_LIBRARY_DEBUG=/home/software/protobuf-3.5.1-install/lib/libprotobuf.so \</span><br><span class="line">      -D Protobuf_LITE_LIBRARIES=/home/software/protobuf-3.5.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">      -D Protobuf_LITE_LIBRARY=/home/software/protobuf-3.5.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">      -D Protobuf_LITE_LIBRARY_DEBUG=/home/software/protobuf-3.5.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">      -D Protobuf_PROTOC_EXECUTABLE=/home/software/protobuf-3.5.1-install/bin/protoc \</span><br><span class="line">      -D Protobuf_PROTOC_LIBRARIES=/home/software/protobuf-3.5.1-install/lib/libprotoc.so \</span><br><span class="line">      -D Protobuf_PROTOC_LIBRARY=/home/software/protobuf-3.5.1-install/lib/libprotoc.so \</span><br><span class="line">      -D Protobuf_PROTOC_LIBRARY_DEBUG=/home/software/protobuf-3.5.1-install/lib/libprotoc.so \</span><br><span class="line">      -D PYTHON3_EXECUTABLE=/root/miniconda3/bin/python \</span><br><span class="line">      -D PYTHON3_INCLUDE_DIR=/root/miniconda3/include/python3.6m \</span><br><span class="line">      -D PYTHON3_LIBRARY=/root/miniconda3/lib/libpython3.6m.so \</span><br><span class="line">      -D PYTHON3_NUMPY_INCLUDE_DIRS=/root/miniconda3/lib/python3.6/site-packages/numpy/core/include \</span><br><span class="line">      -D INSTALL_PYTHON_EXAMPLES=OFF -D OPENCV_SKIP_PYTHON_LOADER=ON \</span><br><span class="line">      -D ZLIB_LIBRARY=/home/software/zlib-1.2.11-install/lib/libz.so \</span><br><span class="line">      -D ZLIB_INCLUDE_DIR=/home/software/zlib-1.2.11-install/include \</span><br><span class="line">      -D PNG_LIBRARY=/home/software/libpng-1.6.37-install/lib/libpng.so \</span><br><span class="line">      -D PNG_PNG_INCLUDE_DIR=/home/software/libpng-1.6.37-install/include \</span><br><span class="line">      -D JPEG_LIBRARY=/home/software/jpeg-9c-install/lib/libjpeg.so \</span><br><span class="line">      -D JPEG_INCLUDE_DIR=/home/software/jpeg-9c-install/include \</span><br><span class="line">      -D HDF5_LIBRARIES=/root/miniconda3/lib/libhdf5_cpp.so \</span><br><span class="line">      -D HDF5_INCLUDE_DIRS=/root/miniconda3/include \</span><br><span class="line">      -D GLOG_LIBRARY=/home/software/glog-0.4.0-install/lib/libglog.so \</span><br><span class="line">      -D GLOG_INCLUDE_DIR=/home/software/glog-0.4.0-install/include \</span><br><span class="line">      ..</span><br><span class="line">make -j &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>如果报下载<code>boostdesc_bgm.i</code>等i文件错误，到该<a href="https://github.com/opencv/opencv_contrib/issues/1301" target="_blank" rel="noopener">issue</a>下下载，放到指定路径(修改下载地址为本地file://)，其他下载错误同理。若是hash验证不通过，则修改对应cmakelist里的hash值为actual值就行。</p><p>要是报c++内部错误，可能是内存炸了，<code>make -j</code>改小点（如<code>make -j4</code>）。</p><p>安装完成后，到安装路径（<code>CMAKE_INSTALL_PREFIX=/home/software/opencv-3.4.4-install</code>）的python目录下，可以发现<code>python-3.6</code>文件夹，里面都有<code>cv2.cpython-36m-x86_64-linux-gnu.so</code>文件，到对应python环境<code>lib/python3.6/site-packages</code>下，建立so文件的软链接（如到<code>/root/miniconda3/lib/python3.6/site-packages</code>下执行:<code>ln -s /home/software/opencv-3.4.4-install/python/python-3.6/cv2.cpython-36m-x86_64-linux-gnu.so /root/miniconda3/lib/python3.6/site-packages/cv2.so</code>）； 最后，检查是否安装成功，也可建立对应的<code>opencv.pc</code>文件，并添加到PATH路径。</p><p><strong>添加所有库路径</strong>，<code>vi /root/.bashrc</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">export BOOST_PATH=/home/software/boost_1_68_0-install</span><br><span class="line">export CMAKE_PATH=/home/software/cmake-3.15.0-rc3-install</span><br><span class="line">export DOXYGEN_PATH=/home/software/doxygen-Release_1_8_15-install</span><br><span class="line">export GFLAGS_PATH=/home/software/gflags-2.2.0-install</span><br><span class="line">export GLOG_PATH=/home/software/glog-0.4.0-install</span><br><span class="line">export HDF5_PATH=/home/software/hdf5-1.8.21-install</span><br><span class="line">export JPEG_PATH=/home/software/jpeg-9c-install</span><br><span class="line">export LEVELDB_PATH=/home/software/leveldb-1.22-install</span><br><span class="line">export LIBPNG_PATH=/home/software/libpng-1.6.37-install</span><br><span class="line">export LIBTOOL_PATH=/home/software/libtool-2.4.6-install</span><br><span class="line">export LMDB_PATH=/home/software/lmdb-LMDB_0.9.23-install</span><br><span class="line">export OPENBLAS_PATH=/home/software/OpenBLAS-0.3.6-install</span><br><span class="line">export OPENCV_PATH=/home/software/opencv-3.4.4-install</span><br><span class="line">export PROTOBUF_PATH=/home/software/protobuf-3.5.1-install</span><br><span class="line">export SNAPPY_PATH=/home/software/snappy-1.1.7-install</span><br><span class="line">export ZLIB_PATH=/home/software/zlib-1.2.11-install</span><br><span class="line">export PATH=$DOXYGEN_PATH/bin:$PROTOBUF_PATH/bin:$LIBTOOL_PATH/bin:$CMAKE_PATH/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=$BOOST_PATH/lib:$CMAKE_PATH/lib:$GFLAGS_PATH/lib:$GLOG_PATH/lib:$HDF5_PATH/lib:$JPEG_PATH/lib:$LEVELDB_PATH/lib:$LIBPNG_PATH/lib:$LIBTOOL_PATH/lib:$LMDB_PATH/lib:$OPENBLAS_PATH/lib:$OPENCV_PATH/lib:$PROTOBUF_PATH/lib:$SNAPPY_PATH/lib:$ZLIB_PATH/lib:$LD_LIBRARY_PATH</span><br><span class="line">export C_INCLUDE_PATH=$BOOST_PATH/include:$CMAKE_PATH/include:$GFLAGS_PATH/include:$GLOG_PATH/include:$HDF5_PATH/include:$JPEG_PATH/include:$LEVELDB_PATH/include:$LIBPNG_PATH/include:$LIBTOOL_PATH/include:$LMDB_PATH/include:$OPENBLAS_PATH/include:$OPENCV_PATH/include:$PROTOBUF_PATH/include:$SNAPPY_PATH/include:$ZLIB_PATH/include:$C_INCLUDE_PATH</span><br><span class="line">export CPLUS_INCLUDE_PATH=$BOOST_PATH/include:$CMAKE_PATH/include:$GFLAGS_PATH/include:$GLOG_PATH/include:$HDF5_PATH/include:$JPEG_PATH/include:$LEVELDB_PATH/include:$LIBPNG_PATH/include:$LIBTOOL_PATH/include:$LMDB_PATH/include:$OPENBLAS_PATH/include:$OPENCV_PATH/include:$PROTOBUF_PATH/include:$SNAPPY_PATH/include:$ZLIB_PATH/include:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure><h2 id="安装caffe"><a href="#安装caffe" class="headerlink" title="安装caffe"></a>安装caffe</h2><p>把caffe源码库拷贝下来后，有两种编译caffe的方式：</p><ul><li>在caffe目录下直接 <code>make</code>、 <code>make pycaffe</code> 来构建工程caffe的C++库和Python库；</li><li>先<code>mkdir build</code>后，在<code>build</code>文件夹下<code>cmake</code>，然后再<code>make</code>、<code>make pycaffe</code>。</li></ul><h3 id="对于makefile方法"><a href="#对于makefile方法" class="headerlink" title="对于makefile方法"></a>对于makefile方法</h3><p>主要修改<code>Makefile.config</code>文件，主要修改点有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">USE_CUDNN := 1</span><br><span class="line">OPENCV_VERSION := 3</span><br><span class="line">CUDA_DIR := /usr/local/cuda-8.0  # 选择特定的CUDA安装路径</span><br><span class="line"># 选择特定的Python/Numpy安装include/lib目录</span><br><span class="line">PYTHON_INCLUDE := /usr/local/public/anaconda3/envs/caffe_py35/include \</span><br><span class="line">/usr/local/public/anaconda3/envs/caffe_py35/lib/python3.5/site-packages/numpy/core/include</span><br><span class="line">PYTHON_LIBRARIES := boost_python3 python3.5m</span><br><span class="line">PYTHON_LIB := /usr/local/public/anaconda2/envs/caffe_py3.5/lib /usr/local/lib/</span><br><span class="line">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial</span><br><span class="line">LIBRARY_DIRS := $(PYTHON_LIB) $(CUDA_DIR)/lib64 /usr/local/lib \</span><br><span class="line">    /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial</span><br><span class="line">USE_NCCL := 1 # 多GPU</span><br></pre></td></tr></table></figure><p>同时，也可修改下Makefile文件里的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)</span><br></pre></td></tr></table></figure><h3 id="对于cmake方法"><a href="#对于cmake方法" class="headerlink" title="对于cmake方法"></a>对于cmake方法</h3><p>修改<code>cmake/Dependencies.cmake</code>: 在<code>if(BUILD_python)</code>分支中，<code>if(NOT &quot;${python_version}&quot; VERSION_LESS &quot;3.0.0&quot;)</code>分支中，添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if(NOT Boost_PYTHON_FOUND)</span><br><span class="line">    find_package(Boost 1.46 COMPONENTS &quot;python3&quot;)</span><br><span class="line">    set(Boost_PYTHON_FOUND $&#123;Boost_PYTHON3_FOUND&#125;)</span><br><span class="line">endif()</span><br></pre></td></tr></table></figure><p>需改<code>cmake/Cuda.cmake</code>中（具体可以对照GPU型号和支持的架构进行设置修改V100是70）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set(Caffe_known_gpu_archs &quot;30 35 50 52 61 70&quot;)</span><br></pre></td></tr></table></figure><p>然后到<code>build</code>文件加下，执行cmake：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cd .. &amp;&amp; rm -r build &amp;&amp; mkdir build &amp;&amp; cd build</span><br><span class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line">-D CUDA_TOOLKIT_ROOT_DIR=&quot;/usr/local/cuda&quot; \</span><br><span class="line">-D CUDNN_INCLUDE=&quot;/usr/local/cuda/include&quot; \</span><br><span class="line">-D CUDNN_LIBRARY=&quot;/usr/local/cuda/lib64/libcudnn.so&quot; \</span><br><span class="line">-D CUDA_NVCC_FLAGS=&quot;-D_FORCE_INLINES&quot; -D CMAKE_CXX_FLAGS=&quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11&quot; \</span><br><span class="line">-D PYTHON_LIBRARIES=&quot;/root/miniconda3/lib;/usr/local/lib&quot; \</span><br><span class="line">-D PYTHON_INCLUDE_DIR=/root/miniconda3/include/python3.6m/ \</span><br><span class="line">-D PYTHON_EXECUTABLE=/root/miniconda3/bin/python \</span><br><span class="line">-D python_version=3.6 -D BLAS=Open  -D CUDA_ARCH_NAME=All -D CUDA_NVCC_FLAGS=&quot;-D_FORCE_INLINES&quot; \</span><br><span class="line">-D CUDNN_INCLUDE=&quot;/usr/include&quot; -D CUDNN_LIBRARY=&quot;/usr/lib/x86_64-linux-gnu/libcudnn.so&quot; \</span><br><span class="line">-D Protobuf_INCLUDE_DIR=/home/software/protobuf-2.6.1-install/include \</span><br><span class="line">-D Protobuf_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D Protobuf_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D Protobuf_LITE_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D Protobuf_LITE_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D Protobuf_PROTOC_EXECUTABLE=/home/software/protobuf-2.6.1-install/bin/protoc \</span><br><span class="line">-D Protobuf_PROTOC_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D Protobuf_PROTOC_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D PROTOBUF_INCLUDE_DIR=/home/software/protobuf-2.6.1-install/include \</span><br><span class="line">-D PROTOBUF_INCLUDE_DIRS=/home/software/protobuf-2.6.1-install/include \</span><br><span class="line">-D PROTOBUF_LIBRARIES=&apos;/home/software/protobuf-2.6.1-install/lib/libprotobuf.so;-lpthread&apos; \</span><br><span class="line">-D PROTOBUF_LIBRARY=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D PROTOBUF_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D PROTOBUF_LITE_LIBRARIES=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D PROTOBUF_LITE_LIBRARY=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D PROTOBUF_LITE_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D PROTOBUF_PROTOC_EXECUTABLE=/home/software/protobuf-2.6.1-install/bin/protoc \</span><br><span class="line">-D PROTOBUF_PROTOC_LIBRARIES=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D PROTOBUF_PROTOC_LIBRARY=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D PROTOBUF_PROTOC_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D CMAKE_PREFIX_PATH=&apos;/home/software/boost_1_68_0-install;/home/software/cmake-3.15.0-rc3-install;/home/software/doxygen-Release_1_8_15-install;/home/software/gflags-2.2.0-install;/home/software/glog-0.4.0-install;/home/software/hdf5-1.8.21-install;/home/software/jpeg-9c-install;/home/software/leveldb-1.22-install;/home/software/libpng-1.6.37-install;/home/software/libtool-2.4.6-install;/home/software/lmdb-LMDB_0.9.23-install;/home/software/OpenBLAS-0.3.6-install;/home/software/opencv-3.4.4-install2;/home/software/protobuf-3.5.1-install;/home/software/snappy-1.1.7-install;/home/software/zlib-1.2.11-install/lib&apos; \</span><br><span class="line">-D CMAKE_INSTALL_PREFIX=/home/caffe ..</span><br><span class="line">make -j </span><br><span class="line">make pycaffe</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>Q. 如果的确已经安装protobuf 2.6.1，但还是出现版本不对（older version），可以加入以下编译选项（其实是conda里的protobuf造成的影响）。</p><p>A. 我是将conda中protobuf的头文件的文件夹名由protobuf改为其他名。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-D Protobuf_INCLUDE_DIR=/home/software/protobuf-2.6.1-install/include \</span><br><span class="line">-D Protobuf_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D Protobuf_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf.so \</span><br><span class="line">-D Protobuf_LITE_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D Protobuf_LITE_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotobuf-lite.so \</span><br><span class="line">-D Protobuf_PROTOC_EXECUTABLE=/home/software/protobuf-2.6.1-install/bin/protoc \</span><br><span class="line">-D Protobuf_PROTOC_LIBRARY_RELEASE=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br><span class="line">-D Protobuf_PROTOC_LIBRARY_DEBUG=/home/software/protobuf-2.6.1-install/lib/libprotoc.so \</span><br></pre></td></tr></table></figure><p>Q. 如果发生protobuf undefined reference的问题？安装glogA. protobuf版本问题，opencv用3.5.1编译，而caffe需要2.6.1，所以依赖不一致。我是把opencv编一个不用protobuf的版本，提供给caffe的。</p><h2 id="保存新镜像"><a href="#保存新镜像" class="headerlink" title="保存新镜像"></a>保存新镜像</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker commit #container-id basic-caffe:2.0.0</span><br><span class="line">docker save basic-caffe:2.0.0 | gzip &gt; basic-caffe.tar.gz</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Caffe </tag>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型剪枝探索和实现小结</title>
      <link href="/2019/07/26/15_%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D%E6%8E%A2%E7%B4%A2%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%B0%8F%E7%BB%93/"/>
      <url>/2019/07/26/15_%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D%E6%8E%A2%E7%B4%A2%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%B0%8F%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>探索模型剪枝方面的一些论文研究，并选择进行实现用到目前项目中（实现部分没有放置在当前ppt中）。</p><a id="more"></a><p>加载需要点时间，需要耐心等待…</p><div class="pdf" target="/resource/network_pruning.pdf" height></div>]]></content>
      
      
      
        <tags>
            
            <tag> 网络剪枝 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对L2正则化、BN层的思考</title>
      <link href="/2019/07/22/14_%E5%AF%B9L2%E6%AD%A3%E5%88%99%E5%8C%96%E3%80%81BN%E5%B1%82%E7%9A%84%E6%80%9D%E8%80%83/"/>
      <url>/2019/07/22/14_%E5%AF%B9L2%E6%AD%A3%E5%88%99%E5%8C%96%E3%80%81BN%E5%B1%82%E7%9A%84%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>对<strong>BN层对网络卷积层权重L2正则化的影响</strong>、<strong>BN层的gamma项正则化作用</strong>、<strong>卷积层权重L2正则化的作用</strong>、<strong>如何更好的调整L2正则项权重、学习率、gamma项权重等超参</strong> 等问题的思考。</p><a id="more"></a><p>涉及的论文：</p><ul><li>主要的思想来源：</li></ul><p><a href="https://arxiv.org/pdf/1706.05350.pdf" target="_blank" rel="noopener">L2 Regularization versus Batch and Weight Normalization</a></p><p><a href="https://arxiv.org/pdf/1809.00846.pdf" target="_blank" rel="noopener">Towards Understanding Regularization in Batch Normalization</a></p><p><a href="https://arxiv.org/pdf/1706.02677.pdf" target="_blank" rel="noopener">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></p><ul><li>引发</li></ul><p><a href="https://arxiv.org/pdf/1708.06519.pdf" target="_blank" rel="noopener">Learning Efficient Convolutional Networks through Network Slimming</a></p><p><a href="https://arxiv.org/pdf/1707.01213.pdf" target="_blank" rel="noopener">Data-Driven Sparse Structure Selection for Deep Neural Networks</a></p><p>之所以开始这一方面的了解，源于对network pruning方面文章（SSS和network slimming）的阅读：</p><ul><li>Network Slimming：增加 BN层中<script type="math/tex">gamma</script>的正则项，而后根据<script type="math/tex">gamma</script>大小进行剪枝：<script type="math/tex; mode=display">L = \sum_{(x,y)}l(f(x,W),y) + \gamma * \sum_{\gamma \in \Gamma}g(\gamma)</script></li><li>Sparse Structure Selection：直接在group/block/channel后新增一层，该层就只有一个scale factor <script type="math/tex">\gamma</script>,然后增加L1正则项<script type="math/tex">|\gamma|</script>；用加速近端梯度下降求解<script type="math/tex">\gamma</script>（软阈值 + 动量梯度下降）。</li></ul><p>复现的过程中，想到一个问题：无论是对于BN层还是自定义层，在降低<script type="math/tex">\gamma</script>以减小正则项时，都可以通过增加对应的卷积层的权重<script type="math/tex">W</script>，从而实现模型不变而损失函数减少的目的（当然，此时模型的损失函数不包含卷积层的权重衰减正则项的话）。而如果损失函数加入卷积层的权重衰减正则项的话，那么此时其实增加了两个超参：<script type="math/tex">\lambda_{conv}</script>和<script type="math/tex">\lambda_{\gamma}</script>（如果是SSS，则是3个超参）。<script type="math/tex">\lambda_{conv}</script>一般设定为默认值0.0005，而<script type="math/tex">\lambda_{\gamma}</script>则通过调参设置而达到 network slimming 的功效。</p><p>那么，BN层<script type="math/tex">\gamma</script>、卷积层权重<script type="math/tex">W</script>、正则化 这三者的关系，其内涵和对模型优化的影响究竟是咋样的呢？带着这样的问题，开启这一小分支的探索和实现（剪枝ppt后续放出）。</p><h2 id="L2正则化与BN层的关系"><a href="#L2正则化与BN层的关系" class="headerlink" title="L2正则化与BN层的关系"></a>L2正则化与BN层的关系</h2><p>下面是batch size和learning rate的延伸。</p><h2 id="Large-batch-training引发的问题"><a href="#Large-batch-training引发的问题" class="headerlink" title="Large batch training引发的问题"></a>Large batch training引发的问题</h2><h2 id="Linear-Scaling-Rule-batch-size、learning-rate、warm-up的纠葛）"><a href="#Linear-Scaling-Rule-batch-size、learning-rate、warm-up的纠葛）" class="headerlink" title="Linear Scaling Rule (batch size、learning rate、warm-up的纠葛）"></a>Linear Scaling Rule (batch size、learning rate、warm-up的纠葛）</h2><p>Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</p>]]></content>
      
      
      
        <tags>
            
            <tag> L2正则化 </tag>
            
            <tag> batch normalizatin </tag>
            
            <tag> warm-up </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GHM论文理解及实现</title>
      <link href="/2019/07/08/13_GHM%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/07/08/13_GHM%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3%E5%8F%8A%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>原论文：<a href="https://arxiv.org/abs/1811.05181" target="_blank" rel="noopener">Gradient Harmonized Single-stage Detector</a></p><p>本文主要基于tf.keras讨论分类部分，论文也提出了适用于检测的方法。实验表明具有一定效果，可以尝试，感觉比<a href="https://arxiv.org/abs/1708.02002" target="_blank" rel="noopener">focal loss</a>要好用。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文针对问题：<strong>one-stage的目标检测算法一直存在的正负/难易样本（样本梯度）失衡问题</strong>。</p><p>在one-stage算法中，负样本的数量要远远大于正样本，而且大多数负样本是简单样本（well-classified）；当然，大多正样本也算是简单样本。简单样本的小梯度，通过样本量的增加，量变引起质变，主导了模型的训练过程。focal loss中通过引入<script type="math/tex">\alpha</script>大大降低简单样本的分类损失，以平衡正负/难易样本，但是设计的损失函数<script type="math/tex">L</script>引入两个超参(OHEM只学习困难/loss大的一部分样本，训练有效性降低）：</p><script type="math/tex; mode=display">L = - \sum_{i}^{c} ( \alpha * | p_{i} - p_{i}^{*} |^{\gamma} * p_{i}^{*} * \ln(p_{i}))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">focal_loss</span><span class="params">(y_truth, y_pred, _)</span>:</span></span><br><span class="line">    epsilon = keras.backend.epsilon()</span><br><span class="line">    y_pred = keras.backend.clip(y_pred, epsilon, <span class="number">1.0</span> - epsilon)</span><br><span class="line">    cross_entropy = -y_truth * keras.backend.log(y_pred)</span><br><span class="line">    <span class="comment"># 这里没有区分正负样本的alpha</span></span><br><span class="line">    weight = alpha * keras.backend.pow(keras.backend.abs(y_truth - y_pred), gamma)</span><br><span class="line">    loss = weight * cross_entropy</span><br><span class="line">    loss = keras.backend.sum(loss, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p>本论文认为，模型训练过程中，信息/知识的传导靠的是梯度；只不过梯度的大小，表象刚好是样本的难易/正负。也就是说，正负/难易样本的失衡，其实是<strong>梯度的失衡</strong>！所以想让模型学得更好，应该从更本质的<strong>梯度</strong>入手。故提出gradient harmonizing mechanism（GHM），拟解决模型中的梯度失衡问题。</p><h2 id="我的理解"><a href="#我的理解" class="headerlink" title="我的理解"></a>我的理解</h2><p>梯度调和机制（gradient harmonized mechanism， GHM）其实就是将不同梯度对损失函数的影响，进行基于密度的平衡。（如果为了简单了解，我们暂且可以把密度理解为样本数量）</p><h3 id="调和机制（harmonized-mechanism）"><a href="#调和机制（harmonized-mechanism）" class="headerlink" title="调和机制（harmonized mechanism）"></a>调和机制（harmonized mechanism）</h3><p>这里把harmonized mechanism翻译为调和机制，其实是调和有取倒数的意思。</p><h4 id="基于类别平衡的损失（class-balanced-loss）"><a href="#基于类别平衡的损失（class-balanced-loss）" class="headerlink" title="基于类别平衡的损失（class-balanced loss）"></a>基于类别平衡的损失（class-balanced loss）</h4><p>可以从样本的类别不平衡来理解：如果有10个类<script type="math/tex">A</script>的样本，2个类<script type="math/tex">B</script>的样本，那么基于类别平衡的损失为：</p><script type="math/tex; mode=display">L = \frac{12}{10} * \sum_{i \in A}(L_{i}) + \frac{12}{2} * \sum_{i \in B}(L_{i})</script><p>其中，10可以理解为类别<script type="math/tex">A</script>的密度，2可以理解为类别<script type="math/tex">B</script>的密度。</p><p>推广到多个类别可得：</p><script type="math/tex; mode=display">L = \sum_{i}^{N}( \frac{N}{M_{i}} * L_{i} )</script><p>其中，<script type="math/tex">N</script>是样本总数，<script type="math/tex">M_{i}</script>是样本<script type="math/tex">i</script>所属的类别的密度，<script type="math/tex">L_{i}</script>是样本<script type="math/tex">i</script>的损失。以上如果取平均损失函数，则需要乘上<script type="math/tex">\frac{1}{N}</script>。</p><h4 id="基于梯度平衡的损失（gradient-balanced-loss）"><a href="#基于梯度平衡的损失（gradient-balanced-loss）" class="headerlink" title="基于梯度平衡的损失（gradient-balanced loss）"></a>基于梯度平衡的损失（gradient-balanced loss）</h4><p>这里，我们将<strong>基于类别的平衡</strong>推广到<strong>基于梯度的平衡</strong>：</p><script type="math/tex; mode=display">L = \sum_{i}^{N}( \frac{N}{GD_{g_{i}}} * L_{g_{i}} )</script><p>其中，<script type="math/tex">N</script>是样本总数，<script type="math/tex">g_{i}</script>是样本<script type="math/tex">i</script>的梯度，<script type="math/tex">GD_{g_{i}}</script>是梯度<script type="math/tex">g_{i}</script>的密度，<script type="math/tex">L_{g_{i}}=L_{i}</script>是样本<script type="math/tex">i</script>的损失。</p><p>也就是说，用样本梯度的密度取倒数，乘上样本损失，便可以平衡不同梯度区域的损失。</p><h3 id="为什么需要调和？"><a href="#为什么需要调和？" class="headerlink" title="为什么需要调和？"></a>为什么需要调和？</h3><p>基于类别的平衡，在实际的数据分析场景中，也要case-by-case分析是否适用。那么，<strong>基于梯度的平衡是否科学</strong>呢？作者给出了下图的解释（图中还包含了cross-entropy和focal-loss的梯度加和方式）：</p><p align="center">    <img src="/images/GHM%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3%E5%8F%8A%E5%AE%9E%E7%8E%B0/GHM_insight.jpg"></p><p>最左边的图是样本的梯度分布，梯度小的表示已经被模型学习到的了（容易样本），梯度大的表示模型很难学到（困难样本）。这两种样本，梯度密度都比较大，主导了整个模型的训练方向。而作者认为，学到的了可以不用学了，没有学到的可能是异常样本，也不用学了；我们这时候应该提升模型，学习中间那段梯度密度较小、还有信息可以学习的样本。</p><p>求解出整个样本集梯度的概率密度的调和曲线（1/概率密度，中间那张图），来调和原始的梯度（也就是与左图相乘），得到最终的模型回传梯度（最右边的图）。</p><p>和focal loss和OHEM的比较来看，改进源于更本质的角度——模型的梯度（当然，这里的梯度并不是整个模型的所有参数<script type="math/tex">W</script>构成的梯度，而是简化为最后一层sigmoid回传的梯度；同时也不是指梯度向量，而是梯度向量的L1范数）。</p><p>以上，便是论文的核心理解，接下来掰一掰公式和实现。</p><h2 id="Gradient-Harmonizing-Mechanism-——-GHM-C-Loss"><a href="#Gradient-Harmonizing-Mechanism-——-GHM-C-Loss" class="headerlink" title="Gradient Harmonizing Mechanism —— GHM-C Loss"></a>Gradient Harmonizing Mechanism —— GHM-C Loss</h2><p>原论文主要针对的是sigmoid二分类情况，我泛化为softmax来分析。</p><p>回过头来看一下GHM的损失函数为：</p><script type="math/tex; mode=display">L = \frac{1}{K} * \sum_{i}^{K}( \frac{N}{GD_{g_{i}}} * L_{g_{i}} )</script><p>其中，<script type="math/tex">K</script>是batch size，最重要的部分在于求解<strong>梯度密度<script type="math/tex">GD_{g_{i}}</script></strong>上，论文通过两个机制来近似这个梯度密度：</p><ol><li>将梯度取值区间(0, 1)切割为多个bin，统计不同bin的梯度数量R，作为梯度密度（论文中梯度密度调和参数是<script type="math/tex">\beta_{i}=\frac{N}{GD_{g_{i}}},GD_{g_{i}}=\frac{R_{i}}{\epsilon},\epsilon=\frac{1}{bin}</script>）；</li><li>用逐batch的指数加权移动平均(EMA)来近似总样本下的梯度密度<script type="math/tex">S_{i}^{t}=\alpha S_{i}^{t-1}+(1-\alpha)R_{i}^{t}</script>。</li></ol><p>cross-entropy的损失函数是：</p><script type="math/tex; mode=display">L = -\sum_{i}^{c}(p_{i}^{*} * \ln(p_{i}))</script><p>其中，<script type="math/tex">p_{i}^{*}</script>指真实类别概率，预测类别概率为<script type="math/tex">p_{i}=\frac{e^{z_{i}}}{\sum_{j}e^{z_{j}}}</script>； 代入计算梯度得 （与论文中针对sigmoid的推导结果是一致的）：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial x_{i}} = p_{i} - p_{i}^{*}</script><p> 综上，可得求解GHM-C Loss：</p><ol><li><script type="math/tex">|\frac{\partial L}{\partial x_{i}}| = |p_{i} - p_{i}^{*}|</script>；</li><li>统计<script type="math/tex">R(g)</script>（<script type="math/tex">g=|p-p^{*}|</script> 所在梯度区间<script type="math/tex">[(i-1)*\epsilon, i*\epsilon]</script>的样本数）；</li><li>指数加权移动平均计算<script type="math/tex">S(g)</script>；</li><li>计算梯度密度 <script type="math/tex">GD(g) = \frac{S(g)}{\epsilon} = S(g) * M</script>；</li><li>计算损失 <script type="math/tex">L = \sum_{i}(\frac{I(x_{i})}{GD(g_i)})</script>。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_categorical_ghm_loss</span><span class="params">(bins=<span class="number">30</span>, momentum=<span class="number">0.75</span>)</span>:</span></span><br><span class="line">    <span class="string">""" 返回多分类 GHM 损失函数：</span></span><br><span class="line"><span class="string">            把每个区间上的梯度做平均，也就是说把梯度拉平，回推到公式上等价于把loss做平均</span></span><br><span class="line"><span class="string">    Formula:</span></span><br><span class="line"><span class="string">        loss = sum(crossentropy_loss(p_i,p*_i) / GD(g_i))</span></span><br><span class="line"><span class="string">        GD(g) = S_ind(g) / delta = S_ind(g) * M</span></span><br><span class="line"><span class="string">        S_ind(g) = momentum * S_ind(g) + (1 - momentum) * R_ind(g)</span></span><br><span class="line"><span class="string">        R_ind(g)是 g=|p-p*| 所在梯度区间[(i-1)delta, i*delta]的样本数</span></span><br><span class="line"><span class="string">        M = 1/delta，这个是个常数，理论上去掉只有步长影响</span></span><br><span class="line"><span class="string">    Parameters: （论文默认）</span></span><br><span class="line"><span class="string">        bins -- 区间个数，default 30</span></span><br><span class="line"><span class="string">        momentum -- 使用移动平均来求区间内样本数，动量部分系数，论文说不敏感</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 区间边界</span></span><br><span class="line">    edges = np.array([i/bins <span class="keyword">for</span> i <span class="keyword">in</span> range(bins + <span class="number">1</span>)])</span><br><span class="line">    edges = np.expand_dims(np.expand_dims(edges, axis=<span class="number">-1</span>), axis=<span class="number">-1</span>)</span><br><span class="line">    acc_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> momentum &gt; <span class="number">0</span>:</span><br><span class="line">        acc_sum = tf.zeros(shape=(bins,), dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ghm_class_loss</span><span class="params">(y_truth, y_pred, valid_mask)</span>:</span></span><br><span class="line">        epsilon = keras.backend.epsilon()</span><br><span class="line">        y_pred = keras.backend.clip(y_pred, epsilon, <span class="number">1.0</span> - epsilon)</span><br><span class="line">        <span class="comment"># 0. 计算本次mini-batch的梯度分布：R_ind(g)</span></span><br><span class="line">        gradient = keras.backend.abs(y_truth - y_pred)</span><br><span class="line">        <span class="comment"># 获取概率最大的类别下标，将该类别的梯度做为该标签的梯度代表</span></span><br><span class="line">        <span class="comment"># 没有这部分就是每个类别的梯度都参与到GHM，实验表明没有这部分会更好些</span></span><br><span class="line">        <span class="comment"># truth_indices_1 = keras.backend.expand_dims(keras.backend.argmax(y_truth, axis=1))</span></span><br><span class="line">        <span class="comment"># truth_indices_0 = keras.backend.expand_dims(keras.backend.arange(start=0,</span></span><br><span class="line">        <span class="comment">#                                                                  stop=tf.shape(y_pred)[0],</span></span><br><span class="line">        <span class="comment">#                                                                  step=1, dtype='int64'))</span></span><br><span class="line">        <span class="comment"># truth_indices = keras.backend.concatenate([truth_indices_0, truth_indices_1])</span></span><br><span class="line">        <span class="comment"># main_gradient = tf.gather_nd(gradient, truth_indices)</span></span><br><span class="line">        <span class="comment"># gradient = tf.tile(tf.expand_dims(main_gradient, axis=-1), [1, y_pred.shape[1]])</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 求解各个梯度所在的区间，并落到对应区间内进行密度计数</span></span><br><span class="line">        grads_bin = tf.logical_and(tf.greater_equal(gradient, edges[:<span class="number">-1</span>, :, :]), tf.less(gradient, edges[<span class="number">1</span>:, :, :]))</span><br><span class="line">        valid_bin = tf.boolean_mask(grads_bin, valid_mask, name=<span class="string">'valid_gradient'</span>, axis=<span class="number">1</span>)</span><br><span class="line">        valid_bin = tf.reduce_sum(tf.cast(valid_bin, dtype=tf.float32), axis=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 2. 更新指数移动平均后的梯度分布：S_ind(g)</span></span><br><span class="line">        <span class="keyword">nonlocal</span> acc_sum</span><br><span class="line">        acc_sum = tf.add(momentum * acc_sum, (<span class="number">1</span> - momentum) * valid_bin, name=<span class="string">'update_bin_number'</span>)</span><br><span class="line">        <span class="comment"># sample_num = tf.reduce_sum(acc_sum)  # 是否乘以总数，乘上效果反而变差了</span></span><br><span class="line">        <span class="comment"># 3. 计算本次mini-batch不同loss对应的梯度密度：GD(g)</span></span><br><span class="line">        position = tf.slice(tf.where(grads_bin), [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">-1</span>, <span class="number">2</span>])</span><br><span class="line">        value = tf.gather_nd(acc_sum, tf.slice(tf.where(grads_bin), [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">-1</span>, <span class="number">1</span>]))  <span class="comment"># * bins</span></span><br><span class="line">        grad_density = tf.sparse.SparseTensor(indices=position, values=value,</span><br><span class="line">                                              dense_shape=tf.shape(gradient, out_type=tf.int64))</span><br><span class="line">        grad_density = tf.sparse.to_dense(grad_density, validate_indices=<span class="literal">False</span>)</span><br><span class="line">        grad_density = grad_density * tf.expand_dims(valid_mask, <span class="number">-1</span>) + (<span class="number">1</span> - tf.expand_dims(valid_mask, <span class="number">-1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. 计算本次mini-batch不同样本的损失：loss</span></span><br><span class="line">        cross_entropy = -y_truth * keras.backend.log(y_pred)</span><br><span class="line">        <span class="comment"># loss = cross_entropy / grad_density * sample_num</span></span><br><span class="line">        loss = cross_entropy / grad_density</span><br><span class="line">        loss = keras.backend.sum(loss, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        # 调试用，打印tensor</span></span><br><span class="line"><span class="string">        print_op = tf.print('acc_sum: ', acc_sum, '\n',</span></span><br><span class="line"><span class="string">                            'grad_density: ', grad_density, '\n',</span></span><br><span class="line"><span class="string">                            'cross_entropy: ', cross_entropy, '\n',</span></span><br><span class="line"><span class="string">                            'loss:', loss, '\n',</span></span><br><span class="line"><span class="string">                            '\n',</span></span><br><span class="line"><span class="string">                            '=================================================\n',</span></span><br><span class="line"><span class="string">                            summarize=100)</span></span><br><span class="line"><span class="string">        with tf.control_dependencies([print_op]):</span></span><br><span class="line"><span class="string">            return tf.identity(loss)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    <span class="keyword">return</span> ghm_class_loss</span><br></pre></td></tr></table></figure><h2 id="Gradient-Harmonizing-Mechanism-——-GHM-R-Loss"><a href="#Gradient-Harmonizing-Mechanism-——-GHM-R-Loss" class="headerlink" title="Gradient Harmonizing Mechanism —— GHM-R Loss"></a>Gradient Harmonizing Mechanism —— GHM-R Loss</h2><p>一般的回归损失是：</p><script type="math/tex; mode=display">SL_{1}(d) =\left\{\begin{matrix}\frac{d^{2}}{2\delta} & if  |d| <= \delta \\|d| - \frac{\delta}{2} & otherwise\end{matrix}\right.</script><p>这样得到的梯度为：</p><script type="math/tex; mode=display">\frac{\partial SL_{1}}{\partial d} =\left\{\begin{matrix}\frac{d}{\delta} & if \; |d| <= \delta \\sgn(d) & otherwise\end{matrix}\right.\Rightarrow   \vee |d| > \delta, |\frac{\partial SL_{1}}{\partial d}| = 1</script><p>由于大部分为梯度为1，没法计算梯度密度。故改进回归损失为：</p><script type="math/tex; mode=display">ASL_{1}(d) = \sqrt{(d^{2} + \mu_{2})} - \mu\Rightarrow\frac{\partial ASL_{1}(d)}{\partial d} = \frac{d}{\sqrt{(d^{2} + \mu_{2})}}</script><p>然后按照 GHM-C Loss 的步骤计算 GHM-R Loss即可（按经验<script type="math/tex">u=0.02</script>）。</p><p align="center">    <img src="/images/GHM%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3%E5%8F%8A%E5%AE%9E%E7%8E%B0/regression_harmonized_gradient.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> GHM </tag>
            
            <tag> 损失函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>车牌识别AI技术的思考</title>
      <link href="/2019/05/10/12_%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABAI%E6%8A%80%E6%9C%AF%E7%9A%84%E6%80%9D%E8%80%83/"/>
      <url>/2019/05/10/12_%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABAI%E6%8A%80%E6%9C%AF%E7%9A%84%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p>车辆牌照的识别是基于图像分割和图像识别理论，对含有车辆号牌的图像进行分析处理，从而确定牌照在图像中的位置，并进一步提取和识别出文本字符。</p><p>识别步骤概括为：<strong>车牌定位、车牌提取、字符识别</strong>。三个步骤相辅相成，各自的有效性都较高，整体的识别率才会提高。</p><a id="more"></a><h2 id="车牌检测"><a href="#车牌检测" class="headerlink" title="车牌检测"></a>车牌检测</h2><p>主要分为2种技术方向来分析：</p><ol><li>回归框检测；</li><li>关键点检测</li></ol><p>传统图像分割 基于边缘、颜色、形状特征，或使用HOG、LBP、Haar特征提取方法，受环境（亮度、对比度等）、场景影响严重，这里按下不表。</p><h3 id="车牌检测：回归框"><a href="#车牌检测：回归框" class="headerlink" title="车牌检测：回归框"></a>车牌检测：回归框</h3><p><strong>单阶段目标检测</strong>：使用one-stage检测算法定位车牌。</p><blockquote><p>优势：</p><ul><li>框架简单；</li><li>检测速度快，适用于多车牌。</li></ul><p>不足：</p><ul><li>受车牌角度影响严重，适用于角度变化不大的场景</li></ul></blockquote><h3 id="车牌检测：关键点"><a href="#车牌检测：关键点" class="headerlink" title="车牌检测：关键点"></a>车牌检测：关键点</h3><p><strong>MTCNN</strong>：图像金字塔 + cascade CNN</p><blockquote><p>优势：</p><ul><li>整体模型小，存储及显存占用小；</li><li>推理速度与车牌数量相关，车牌数量少时推理速度快；</li></ul><p>不足：</p><ul><li>受第一个阶段的影响，车牌的角度也受一定的限制（可设置H:W=1:3或3:5等），或者需要额外设计第一阶段的车牌recall方式；</li><li>整个训练流程分为3个阶段，比较繁琐，特别需要联合调参以达到商业指标；</li><li>需要支持batch推理模式，才能发挥出MTCNN的推理速度优势；</li></ul></blockquote><p><strong>Deepercut/ Pose Residual Network/ OpenPose</strong>：全卷积得heatmap + 关键点归属</p><blockquote><p>优势：</p><ul><li>速度较快；</li><li>不限车牌数；</li><li>精度可以；</li></ul></blockquote><p><strong>(Stack) Hourglass</strong>：Hourglass系列</p><blockquote><p>优势：</p><ul><li>可以与单阶段目标检测结合，加上关键点检测；也可直接作为端到端关键点检测（associative embedding）；</li><li>检测精度高；</li></ul><p>不足：</p><ul><li>整体模型较大，速度慢；</li><li>结构设计时，限定了检测的车牌数上限；</li></ul></blockquote><p><strong>两阶段top-down关键点检测</strong>：检测算法+CNN/CPN/stack hourglass等</p><blockquote><p>优势：</p><ul><li>在多车牌场景下，可以获得高准确率及召回率；</li><li>设计灵活；</li></ul><p>不足：</p><ul><li>没形成端到端模型，训练/优化麻烦；</li></ul></blockquote><h3 id="车牌检测总结"><a href="#车牌检测总结" class="headerlink" title="车牌检测总结"></a>车牌检测总结</h3><ul><li>具有极致的速度要求和角度较小的单一场景，可以考虑使用单阶段目标检测算法。</li><li>若车牌角度变化大：则使用关键点检测算法；<ul><li>若有速度要求，单车牌场景可考虑两阶段关键点检测，多车牌场景可考虑Deepercut、Pose Residual Network/openpose；</li><li>若对算力约束不大，角度要求高，多车牌，则可考虑使用复杂二阶段关键点检测、stack hourglass变种等算法。</li></ul></li></ul><h2 id="车牌识别"><a href="#车牌识别" class="headerlink" title="车牌识别"></a>车牌识别</h2><p><strong>GRU/bi-LSTM + CNN + CTC Loss</strong>：</p><blockquote><p>优势：</p><ul><li>先验的空间分割（但对双层车牌，这个先验则变成劣势）</li><li>空间上下文信息（这个信息较少，应该就只有两个：省份简称和首字母、剩余5位车牌中最多2位是字母）</li></ul><p>不足：</p><ul><li>中国车牌不同位置的字符具有不同取值集合，而RNN结构将这些值集放到一起进行预测，失去了不同位的值集先验，并且提升了类别失衡的风险；</li><li>RNN结构使得推理最后分类部分有时序耦合作用，降低推理速度；</li></ul></blockquote><p align="center">    <img src="/images/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABAI%E6%8A%80%E6%9C%AF%E7%9A%84%E6%80%9D%E8%80%83/CNN_LSTM_CTC.png"></p><p><strong>多标签多分类</strong>：</p><blockquote><p>优势：</p><ul><li>速度快；</li><li>结构灵活</li></ul><p>不足：</p><ul><li>没有运用字符间的空间信息</li></ul></blockquote><p align="center">    <img src="/images/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABAI%E6%8A%80%E6%9C%AF%E7%9A%84%E6%80%9D%E8%80%83/multi_label_classification.png"></p><h2 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h2><p><strong>检测与识别端到端优化（如CCPD论文）</strong>：</p><blockquote><p>优势：</p><ul><li>端到端训练与推理；</li></ul><p>不足：</p><ul><li>没法引入其他车牌进行车牌侧的优化；</li><li>不算是主流方法，精度待验证；</li></ul></blockquote><p><strong>检测+字符分割+识别</strong>：</p><blockquote><p>优势：</p><ul><li>复用不同位置的字符样本</li><li>单字符识别更加容易</li></ul><p>不足：</p><ul><li>需要进行字符分割；</li><li>多字符分别识别（也可作为batch），影响速度;</li><li>类别失衡和位置集合信息丢失；</li></ul></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 车牌识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Caffe使用的一些Q&amp;A</title>
      <link href="/2019/04/25/11_Caffe%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9BQ&amp;A/"/>
      <url>/2019/04/25/11_Caffe%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9BQ&amp;A/</url>
      
        <content type="html"><![CDATA[<p>训练好的模型测试效果差？不同层的同名blob变量意味着什么？</p><a id="more"></a><p><strong>Question</strong>: 训练好的模型，部署测试的时候效果极差（相对训练时loss,cls等输出而言）  </p><p><strong>Answer</strong>: 可能的情况有：</p><ul><li><p>deploy.prototxt中，层的name和train.prototxt中对应层不一致。debug过程可用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line">net = caffe.Net(<span class="string">'deploy.prototxt'</span>, <span class="string">'resnet18.caffemodel'</span>, caffe.TEST)</span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</span><br><span class="line"><span class="comment"># 将cv2或者caffe读入数据shape(image_height, image_width, channel_num)变为(channel_num, image_height, image_width)</span></span><br><span class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">net.blobs[<span class="string">"data"</span>].reshape(<span class="number">1</span>, channel_num, image_height, image_width)</span><br><span class="line">image = cv2.imread(<span class="string">'image.jpg'</span>)/<span class="number">255</span></span><br><span class="line">transformed_image = self.transformer.preprocess(<span class="string">'data'</span>, image)</span><br><span class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformed_image</span><br><span class="line">output = net.forward()  <span class="comment"># 输出层数据(batch_size, channel_num, image_height, image_width)</span></span><br><span class="line">print([(k,v[<span class="number">0</span>].data) <span class="keyword">for</span> k,v <span class="keyword">in</span> net.params.items()])</span><br><span class="line">w1 = net.params[<span class="string">'Convolution_top'</span>][<span class="number">0</span>].data  <span class="comment"># 查看网络权重参数，若name不一致，该层可能初始化为0，或随机初始化等不可预期操作</span></span><br><span class="line">b1 = net.params[<span class="string">'Convolution_top'</span>][<span class="number">1</span>].data</span><br><span class="line">feature = = net.blobs[<span class="string">'Convolution_name'</span>].data  <span class="comment"># 查看网络对应name的输出特征</span></span><br></pre></td></tr></table></figure></li><li><p>输入的图片数据，和训练时输入的图片数据预处理不一致。如训练用opencv的<code>cv2.imread(&#39;image.jpg&#39;)</code>，而测试用<code>caffe.io.load_image(&#39;image.jpg&#39;)</code>。因为，<code>cv2.imread()</code>读入的图片是[0, 255]的BRG格式，而<code>caffe.io.load_image()</code>读入的数据是[0, 1]范围的RGB格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line">net = caffe.Net(<span class="string">'deploy.prototxt'</span>, <span class="string">'resnet18.caffemodel'</span>, caffe.TEST)</span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</span><br><span class="line"><span class="comment"># 将cv2或者caffe读入数据shape(image_height, image_width, channel_num)变为(channel_num, image_height, image_width)</span></span><br><span class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))  </span><br><span class="line">transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>))  <span class="comment"># 将channels从RGB变为BGR，这个只有在用caffe.io.load_image()才需要</span></span><br><span class="line">net.blobs[<span class="string">"data"</span>].reshape(<span class="number">1</span>, channel_num, image_height, image_width)</span><br><span class="line"><span class="comment"># 如果用cv2，读入则依据train.prototxt中数据预处理是否用了归一化，考虑cv2.imread('image.jpg')/255进行归一操作</span></span><br><span class="line">image = caffe.io.load_image(<span class="string">'image.jpg'</span>)  </span><br><span class="line">transformed_image = self.transformer.preprocess(<span class="string">'data'</span>, image)</span><br><span class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformed_image</span><br></pre></td></tr></table></figure></li></ul><p><strong>Question</strong>: 在训练模型时，模型加载一半，报出以下错误：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">I0614 06:47:37.005009  6183 layer_factory.hpp:77] Creating layer res4b_res4b_0_split</span><br><span class="line">I0614 06:47:37.005156  6183 net.cpp:84] Creating Layer res4b_res4b_0_split</span><br><span class="line">I0614 06:47:37.005290  6183 net.cpp:406] res4b_res4b_0_split &lt;- res4b</span><br><span class="line">I0614 06:47:37.005432  6183 net.cpp:380] res4b_res4b_0_split -&gt; res4b_res4b_0_split_0</span><br><span class="line">I0614 06:47:37.005589  6183 net.cpp:380] res4b_res4b_0_split -&gt; res4b_res4b_0_split_1</span><br><span class="line">I0614 06:47:37.005784  6183 net.cpp:122] Setting up res4b_res4b_0_split</span><br><span class="line">I0614 06:47:37.005924  6183 net.cpp:129] Top shape: 128 256 6 18 (3538944)</span><br><span class="line">I0614 06:47:37.006058  6183 net.cpp:129] Top shape: 128 256 6 18 (3538944)</span><br><span class="line">I0614 06:47:37.006186  6183 net.cpp:137] Memory required for data: 3266455552</span><br><span class="line"># 以下为两个分支，resnet_v2 residual block</span><br><span class="line"># 第一个分支：conv 1*1，channel翻倍（我这里翻一半256-&gt;384），feature map stride为2（6 * 18 -&gt; 3 * 9）</span><br><span class="line">I0614 06:47:37.006321  6183 layer_factory.hpp:77] Creating layer res5a_branch1</span><br><span class="line">I0614 06:47:37.006469  6183 net.cpp:84] Creating Layer res5a_branch1</span><br><span class="line">I0614 06:47:37.006597  6183 net.cpp:406] res5a_branch1 &lt;- res4b_res4b_0_split_0</span><br><span class="line">I0614 06:47:37.006743  6183 net.cpp:380] res5a_branch1 -&gt; res5a_branch1</span><br><span class="line">I0614 06:47:37.010433  6183 net.cpp:122] Setting up res5a_branch1</span><br><span class="line">I0614 06:47:37.010591  6183 net.cpp:129] Top shape: 128 384 3 9 (1327104)</span><br><span class="line">I0614 06:47:37.010730  6183 net.cpp:137] Memory required for data: 3271763968</span><br><span class="line"># 第二个分支：两个base building block，第一个要负责channel翻倍和feature map stride为2</span><br><span class="line"># BN</span><br><span class="line">I0614 06:47:37.010865  6183 layer_factory.hpp:77] Creating layer bn5a_branch2a</span><br><span class="line">I0614 06:47:37.011039  6183 net.cpp:84] Creating Layer bn5a_branch2a</span><br><span class="line">I0614 06:47:37.011173  6183 net.cpp:406] bn5a_branch2a &lt;- res4b_res4b_0_split_1</span><br><span class="line">I0614 06:47:37.011315  6183 net.cpp:380] bn5a_branch2a -&gt; res5a_branch2a</span><br><span class="line">I0614 06:47:37.011767  6183 net.cpp:122] Setting up bn5a_branch2a</span><br><span class="line">I0614 06:47:37.011909  6183 net.cpp:129] Top shape: 128 256 6 18 (3538944)</span><br><span class="line">I0614 06:47:37.012042  6183 net.cpp:137] Memory required for data: 3285919744</span><br><span class="line"># scale</span><br><span class="line">I0614 06:47:37.012198  6183 layer_factory.hpp:77] Creating layer scale5a_branch2a</span><br><span class="line">I0614 06:47:37.012343  6183 net.cpp:84] Creating Layer scale5a_branch2a</span><br><span class="line">I0614 06:47:37.012476  6183 net.cpp:406] scale5a_branch2a &lt;- res5a_branch2a</span><br><span class="line">I0614 06:47:37.012619  6183 net.cpp:367] scale5a_branch2a -&gt; res5a_branch2a (in-place)</span><br><span class="line">I0614 06:47:37.012815  6183 layer_factory.hpp:77] Creating layer scale5a_branch2a</span><br><span class="line">I0614 06:47:37.013126  6183 net.cpp:122] Setting up scale5a_branch2a</span><br><span class="line">I0614 06:47:37.013267  6183 net.cpp:129] Top shape: 128 256 6 18 (3538944)</span><br><span class="line">I0614 06:47:37.013396  6183 net.cpp:137] Memory required for data: 3300075520</span><br><span class="line"># ReLu</span><br><span class="line">I0614 06:47:37.013535  6183 layer_factory.hpp:77] Creating layer res5a_branch2a_relu</span><br><span class="line">I0614 06:47:37.013675  6183 net.cpp:84] Creating Layer res5a_branch2a_relu</span><br><span class="line">I0614 06:47:37.013814  6183 net.cpp:406] res5a_branch2a_relu &lt;- res5a_branch2a</span><br><span class="line">I0614 06:47:37.013959  6183 net.cpp:367] res5a_branch2a_relu -&gt; res5a_branch2a (in-place)</span><br><span class="line">I0614 06:47:37.014320  6183 net.cpp:122] Setting up res5a_branch2a_relu</span><br><span class="line">I0614 06:47:37.014461  6183 net.cpp:129] Top shape: 128 256 6 18 (3538944)</span><br><span class="line">I0614 06:47:37.014588  6183 net.cpp:137] Memory required for data: 3314231296</span><br><span class="line"># 问题出在这 conv 3*3 pad 1 stride 2 channel 256-&gt;384，这里输出blob（top layer）和输入blob（bottom layer）的大小已经完全不一致</span><br><span class="line"># 但是我在prototxt中，仍给这两个变量命为同一个名，导致两个在进行inplace运算时，caffe尝试reshape而报错</span><br><span class="line">I0614 06:47:37.014735  6183 layer_factory.hpp:77] Creating layer res5a_branch2a</span><br><span class="line">I0614 06:47:37.014889  6183 net.cpp:84] Creating Layer res5a_branch2a</span><br><span class="line">I0614 06:47:37.015050  6183 net.cpp:406] res5a_branch2a &lt;- res5a_branch2a</span><br><span class="line">I0614 06:47:37.015213  6183 net.cpp:367] res5a_branch2a -&gt; res5a_branch2a (in-place)</span><br><span class="line">F0614 06:47:37.033099  6183 cudnn_conv_layer.cpp:138] Check failed: status == CUDNN_STATUS_SUCCESS (3 vs. 0)  CUDNN_STATUS_BAD_PARAM</span><br><span class="line">*** Check failure stack trace: ***</span><br><span class="line">    @     0x7fb4b4a675cd  google::LogMessage::Fail()</span><br><span class="line">    @     0x7fb4b4a69433  google::LogMessage::SendToLog()</span><br><span class="line">    @     0x7fb4b4a6715b  google::LogMessage::Flush()</span><br><span class="line">    @     0x7fb4b4a69e1e  google::LogMessageFatal::~LogMessageFatal()</span><br><span class="line">    @     0x7fb4b5074598  caffe::CuDNNConvolutionLayer&lt;&gt;::Reshape()</span><br><span class="line">    @     0x7fb4b519dddb  caffe::Net&lt;&gt;::Init()</span><br><span class="line">    @     0x7fb4b51a061e  caffe::Net&lt;&gt;::Net()</span><br><span class="line">    @     0x7fb4b51a9775  caffe::Solver&lt;&gt;::InitTrainNet()</span><br><span class="line">    @     0x7fb4b51aaba5  caffe::Solver&lt;&gt;::Init()</span><br><span class="line">    @     0x7fb4b51aaebf  caffe::Solver&lt;&gt;::Solver()</span><br><span class="line">    @     0x7fb4b51bc3d1  caffe::Creator_AdamSolver&lt;&gt;()</span><br><span class="line">    @           0x40bfb3  train()</span><br><span class="line">    @           0x408660  main</span><br><span class="line">    @     0x7fb4b3b9c830  __libc_start_main</span><br><span class="line">    @           0x408fb9  _start</span><br><span class="line">    @              (nil)  (unknown)</span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure></p><p><strong>Answer</strong>：解释如上注释，不同层的同名blob变量可以看成是不同层，在复用c++里已经定义好的数组（inplace），所以数组的shape必须是一致的。</p><p>修改如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">    bottom: &quot;res5a_branch2a&quot;</span><br><span class="line">    top: &quot;res5a_branch2a&quot;</span><br><span class="line">    name: &quot;scale5a_branch2a&quot;</span><br><span class="line">    type: &quot;Scale&quot;</span><br><span class="line">    scale_param &#123;</span><br><span class="line">        bias_term: true</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">    bottom: &quot;res5a_branch2a&quot;</span><br><span class="line">    top: &quot;res5a_branch2a&quot;</span><br><span class="line">    name: &quot;res5a_branch2a_relu&quot;</span><br><span class="line">    type: &quot;ReLU&quot;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">    bottom: &quot;res5a_branch2a&quot;</span><br><span class="line">    top: &quot;res5a_branch2a&quot; -&gt; top: &quot;res5a_branch2b&quot;</span><br><span class="line">    name: &quot;res5a_branch2a&quot;</span><br><span class="line">    type: &quot;Convolution&quot;</span><br><span class="line">    convolution_param &#123;</span><br><span class="line">        num_output: 384</span><br><span class="line">        kernel_size: 3</span><br><span class="line">        pad: 1</span><br><span class="line">        stride: 2</span><br><span class="line">        weight_filler &#123;</span><br><span class="line">            type: &quot;msra&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        bias_term: false</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">    bottom: &quot;res5a_branch2a&quot; -&gt; bottom: &quot;res5a_branch2b&quot;</span><br><span class="line">    top: &quot;res5a_branch2b&quot;</span><br><span class="line">    name: &quot;bn5a_branch2b&quot;</span><br><span class="line">    type: &quot;BatchNorm&quot;</span><br><span class="line">    batch_norm_param&#123;</span><br><span class="line">        use_global_stats: false</span><br><span class="line">        moving_average_fraction: 0.95</span><br><span class="line">    &#125;</span><br><span class="line">    include &#123;</span><br><span class="line">        phase: TRAIN</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">    bottom: &quot;res5a_branch2a&quot; -&gt; bottom: &quot;res5a_branch2b&quot;</span><br><span class="line">    top: &quot;res5a_branch2b&quot;</span><br><span class="line">    name: &quot;bn5a_branch2b&quot;</span><br><span class="line">    type: &quot;BatchNorm&quot;</span><br><span class="line">    batch_norm_param&#123;</span><br><span class="line">        use_global_stats: true</span><br><span class="line">    &#125;</span><br><span class="line">    include &#123;</span><br><span class="line">        phase: TEST</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> Caffe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装Caffe的一些笔记</title>
      <link href="/2019/04/20/10_%E5%AE%89%E8%A3%85Caffe%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/"/>
      <url>/2019/04/20/10_%E5%AE%89%E8%A3%85Caffe%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>主要包含：</p><ol><li>opencv编译安装；</li><li>boost-python3编译安装；</li><li>Caffe make及cmake两种安装方式，bug解决等。</li></ol><a id="more"></a><h2 id="1-安装anaconda"><a href="#1-安装anaconda" class="headerlink" title="1. 安装anaconda"></a>1. 安装anaconda</h2><p>直接到官网下载linux系统最新的anaconda安装shell脚本，在确保联网的情况下，bash AnacondaXXX.sh就行。</p><h2 id="2-创建anaconda的Python2-7及Python3-5环境"><a href="#2-创建anaconda的Python2-7及Python3-5环境" class="headerlink" title="2. 创建anaconda的Python2.7及Python3.5环境"></a>2. 创建anaconda的Python2.7及Python3.5环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n caffe_py35 python=3.5</span><br><span class="line">conda create -n caffe_py27 python=2.7</span><br></pre></td></tr></table></figure><h2 id="3-安装NVIDIA-GPU驱动、安装CUDA、配置cuDNN"><a href="#3-安装NVIDIA-GPU驱动、安装CUDA、配置cuDNN" class="headerlink" title="3. 安装NVIDIA GPU驱动、安装CUDA、配置cuDNN"></a>3. 安装NVIDIA GPU驱动、安装CUDA、配置cuDNN</h2><h2 id="4-为不同版本的Python，安装支持CUDA的opencv"><a href="#4-为不同版本的Python，安装支持CUDA的opencv" class="headerlink" title="4. 为不同版本的Python，安装支持CUDA的opencv"></a>4. 为不同版本的Python，安装支持CUDA的opencv</h2><p>先到github上，下载opencv项目和opencv-contrib项目（opencv的扩展模块），都解压到目录<code>/home/zhengyuwei/software/opencv</code>下。</p><p>到<code>opencv</code>解压目录下，进入<code>opencv</code>，执行：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">mkdir build</span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">sudo cmake -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line">      <span class="comment">#安装路径 \</span></span><br><span class="line">      -D CMAKE_INSTALL_PREFIX=<span class="string">"/home/zhengyuwei/software/opencv/opencv-install/"</span> \</span><br><span class="line">      -D INSTALL_C_EXAMPLES=ON \</span><br><span class="line">      <span class="comment">#opencv的扩展模块 \</span></span><br><span class="line">      -D OPENCV_EXTRA_MODULES_PATH=<span class="string">"/home/zhengyuwei/software/opencv/opencv_contrib-master/modules"</span> \</span><br><span class="line">      -D BUILD_EXAMPLES=ON \</span><br><span class="line">      -D BUILD_opencv_python2=ON \</span><br><span class="line">      <span class="comment"># 支持CUDA \</span></span><br><span class="line">      -D WITH_FFMPEG=1 \</span><br><span class="line">      -D WITH_TIFF=ON \</span><br><span class="line">      -D WITH_CUDA=ON \</span><br><span class="line">      -D CUDA_GENERATION=Pascal \</span><br><span class="line">      -D ENABLE_FAST_MATH=1 \</span><br><span class="line">      -D CUDA_FAST_MATH=1 \</span><br><span class="line">      -D WITH_CUBLAS=ON \</span><br><span class="line">      -D WITH_LAPACK=OFF \</span><br><span class="line">      -D WITH_GTK=OFF -D WITH_GTK_2_X=OFF -D WITH_MATLAB=OFF -D WITH_QT=ON \</span><br><span class="line">      -D CUDA_NVCC_FLAGS=<span class="string">"-D_FORCE_INLINES"</span> -D ENABLE_CXX11=1 \</span><br><span class="line">      <span class="comment"># 指定protobuf路径，如果出现版本问题，要确定本版本opencv匹配哪个版本的protobuf（我是opencv4.0和protobuf3.7.0）</span></span><br><span class="line">      <span class="comment"># 如果对应版本后，还是出现old/new version导致的error，只好将对应的module排除掉，我排除了dnn：-D BUILD_opencv_dnn=OFF</span></span><br><span class="line">      -D WITH_PROTOBUF=ON -D BUILD_PROTOBUF=OFF -D -BUILD_LIBPROTOBUF_FROM_SOURCES=OFF -D PROTOBUF_UPDATE_FILES=OFF \</span><br><span class="line">      -D ENABLE_PRECOMPILED_HEADERS=ON \</span><br><span class="line">      -D PROTOBUF_INCLUDE_DIR=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/include"</span> \</span><br><span class="line">      -D PROTOBUF_INCLUDE_DIRS=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/include"</span> \</span><br><span class="line">      -D PROTOBUF_LIBRARIES=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf.so;-lpthread"</span> \</span><br><span class="line">      -D PROTOBUF_LIBRARY=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf.so"</span> \</span><br><span class="line">      -D PROTOBUF_LIBRARY_DEBUG=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf.so"</span> \</span><br><span class="line">      -D PROTOBUF_LITE_LIBRARIES=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf-lite.so"</span> \</span><br><span class="line">      -D PROTOBUF_LITE_LIBRARY=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf-lite.so"</span> \</span><br><span class="line">      -D PROTOBUF_LITE_LIBRARY_DEBUG=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotobuf-lite.so"</span> \</span><br><span class="line">      -D PROTOBUF_PROTOC_EXECUTABLE=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/bin/protoc"</span> \</span><br><span class="line">      -D PROTOBUF_PROTOC_LIBRARIES=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotoc.so"</span> \</span><br><span class="line">      -D PROTOBUF_PROTOC_LIBRARY=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotoc.so"</span> \</span><br><span class="line">      -D PROTOBUF_PROTOC_LIBRARY_DEBUG=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libprotoc.so"</span> \</span><br><span class="line">      <span class="comment"># 支持Python2.7 \</span></span><br><span class="line">      -D PYTHON2_EXECUTABLE=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27/bin/python"</span> \</span><br><span class="line">      -D PYTHON2_INCLUDE_DIR=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27/include/python2.7"</span> \</span><br><span class="line">      -D PYTHON2_LIBRARY=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27/lib/libpython2.7.so"</span> \</span><br><span class="line">      -D PYTHON2_NUMPY_INCLUDE_DIRS=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27/lib/python2.7/site-packages/numpy/core/include"</span> \</span><br><span class="line">      <span class="comment"># 支持Python3.5 \</span></span><br><span class="line">      -D PYTHON3_EXECUTABLE=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/bin/python"</span> \</span><br><span class="line">      -D PYTHON3_INCLUDE_DIR=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/include/python3.5m"</span> \</span><br><span class="line">      -D PYTHON3_LIBRARY=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/libpython3.5m.so"</span> \</span><br><span class="line">      -D PYTHON3_NUMPY_INCLUDE_DIRS=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib/python3.5/site-packages/numpy/core/include"</span> \</span><br><span class="line">      -D INSTALL_PYTHON_EXAMPLES=ON \</span><br><span class="line">      -D OPENCV_SKIP_PYTHON_LOADER=ON ..</span><br><span class="line"><span class="comment"># 这里会打印配置信息，确保configure done</span></span><br><span class="line">sudo make -j</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></p><p>Q1: unsupported/Eigen/…不存在？A1: 到eigen github下载压缩包，解压后里面有<code>unsupported</code>目录，移到能找到的<code>include</code>文件夹下。</p><p>Q2: <code>opencv-3.4/modules/dnn/misc/tensorflow/graph.pb.h:17:2: error: #error This file was generated by an older version of protoc which is</code> protobuf版本问题？A2: 增加cmake选项<code>-D BUILD_PROTOBUF=OFF -D BUILD_opencv_dnn=OFF</code>。</p><p>安装完成后，到安装路径（<code>CMAKE_INSTALL_PREFIX=/home/zhengyuwei/software/opencv/opencv-install</code>）的<code>lib</code>目录下，可以发现<code>python2.7</code>和<code>python3.5</code>两个文件夹，里面都有<code>site-packages/cv2.XXX</code>文件，到对应python环境<code>lib/pythonX.X/site-packages</code>下，建立so文件的软链接：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/zhengyuwei/software/anaconda3/envs/caffe_py27/lib</span><br><span class="line">ln -s /home/zhengyuwei/software/opencv/opencv-install/lib/python2.7/site-packages/cv2.so \</span><br><span class="line">/home/zhengyuwei/software/anaconda3/envs/caffe_py27/lib/python2.7/site-packages/cv2.so</span><br></pre></td></tr></table></figure></p><p>最后，检查是否安装成功，也可建立对应的opencv.pc文件，并添加到PATH路径。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># opencv.pc</span></span><br><span class="line"><span class="comment"># Package Information for pkg-config</span></span><br><span class="line"></span><br><span class="line">prefix=/home/zhengyuwei/software/opencv/opencv-install</span><br><span class="line">exec_prefix=<span class="variable">$&#123;prefix&#125;</span></span><br><span class="line">libdir=<span class="variable">$&#123;exec_prefix&#125;</span>/lib</span><br><span class="line">includedir_old=<span class="variable">$&#123;prefix&#125;</span>/include/opencv4</span><br><span class="line">includedir_new=<span class="variable">$&#123;prefix&#125;</span>/include</span><br><span class="line"></span><br><span class="line">Name: OpenCV</span><br><span class="line">Description: Openurce Computer Vision Library</span><br><span class="line">Version: 4.1.0-pre</span><br><span class="line">Libs: -L<span class="variable">$&#123;libdir&#125;</span> -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_calib3d -lopencv_ccalib -lopencv_core -lopencv_cudaarithm -lopencv_cudabgsegm -lopencv_cudacodec -lopencv_cudafeatures2d -lopencv_cudafilters -lopencv_cudaimgproc -lopencv_cudalegacy -lopencv_cudaobjdetect -lopencv_cudaoptflow -lopencv_cudastereo -lopencv_cudawarping -lopencv_cudev -lopencv_datasets -lopencv_dnn_objdetect -lopencv_dnn -lopencv_dpm -lopencv_face -lopencv_features2d -lopencv_flann -lopencv_freetype -lopencv_fuzzy -lopencv_gapi -lopencv_hdf -lopencv_hfs -lopencv_highgui -lopencv_imgcodecs -lopencv_img_hash -lopencv_imgproc -lopencv_line_descriptor -lopencv_ml -lopencv_objdetect -lopencv_optflow -lopencv_phase_unwrapping -lopencv_photo -lopencv_plot -lopencv_quality -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_shape -lopencv_stereo -lopencv_stitching -lopencv_structured_light -lopencv_superres -lopencv_surface_matching -lopencv_text -lopencv_tracking -lopencv_videoio -lopencv_video -lopencv_videostab -lopencv_xfeatures2d -lopencv_ximgproc -lopencv_xobjdetect -lopencv_xphoto</span><br><span class="line">Libs.private: -L/usr/<span class="built_in">local</span>/public/anaconda3/lib -lpng -lz -L/usr/lib/x86_64-linux-gnu -ljasper -ljpeg -lImath -lIlmImf -lIex -lHalf -lIlmThread -lgtk-3 -lgdk-3 -lpangocairo-1.0 -lpango-1.0 -latk-1.0 -lcairo-gobject -lcairo -lgdk_pixbuf-2.0 -lgio-2.0 -lgobject-2.0 -lglib-2.0 -lgthread-2.0 -lgstbase-1.0 -lgstreamer-1.0 -lgstvideo-1.0 -lgstapp-1.0 -lgstriff-1.0 -lgstpbutils-1.0 -ldc1394 -lavcodec -lavformat -lavutil -lswscale -ldl -lm -lpthread -lrt -L/usr/lib -lopenblas -L/usr/<span class="built_in">local</span>/cuda-8.0 -l64</span><br><span class="line">Cflags: -I<span class="variable">$&#123;includedir_old&#125;</span> -I<span class="variable">$&#123;includedir_new&#125;</span></span><br></pre></td></tr></table></figure></p><h2 id="5-安装caffe："><a href="#5-安装caffe：" class="headerlink" title="5. 安装caffe："></a>5. 安装caffe：</h2><p>把caffe源码库拷贝下来后，有两种编译caffe的方式：</p><ul><li>在caffe目录下直接 make、 make pycaffe 来构建工程caffe的C++库和Python库；</li><li>先mkdir build后，在build文件夹下cmake，然后再make、make pycaffe。</li></ul><h3 id="对于makefile方法"><a href="#对于makefile方法" class="headerlink" title="对于makefile方法"></a>对于makefile方法</h3><p>主要修改 <strong>Makefile.config</strong> 文件，主要修改点有：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">USE_CUDNN := 1</span><br><span class="line">OPENCV_VERSION := 3</span><br><span class="line"><span class="comment"># 选择特定的CUDA安装路径</span></span><br><span class="line">CUDA_DIR := /usr/<span class="built_in">local</span>/cuda-8.0</span><br><span class="line"><span class="comment"># 选择特定的Python/Numpy安装include/lib目录</span></span><br><span class="line">PYTHON_INCLUDE := /usr/<span class="built_in">local</span>/public/anaconda3/envs/caffe_py35/include \</span><br><span class="line">/usr/<span class="built_in">local</span>/public/anaconda3/envs/caffe_py35/lib/python3.5/site-packages/numpy/core/include</span><br><span class="line">PYTHON_LIBRARIES := boost_python3 python3.5m</span><br><span class="line">PYTHON_LIB := /usr/<span class="built_in">local</span>/public/anaconda2/envs/caffe_py3.5/lib /usr/<span class="built_in">local</span>/lib/</span><br><span class="line">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class="built_in">local</span>/include /usr/include/hdf5/serial</span><br><span class="line">LIBRARY_DIRS := $(PYTHON_LIB) $(CUDA_DIR)/lib64 /usr/<span class="built_in">local</span>/lib \</span><br><span class="line">    /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial</span><br><span class="line"><span class="comment"># 多GPU</span></span><br><span class="line">USE_NCCL := 1</span><br></pre></td></tr></table></figure></p><p>同时，也可修改下Makefile文件里的：<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NVCCFLAGS += -D_FORCE_INLINES -ccbin=<span class="variable">$(CXX)</span> -Xcompiler -fPIC <span class="variable">$(COMMON_FLAGS)</span></span><br></pre></td></tr></table></figure></p><h3 id="对于cmake方法"><a href="#对于cmake方法" class="headerlink" title="对于cmake方法"></a>对于cmake方法</h3><p>修改cmake/Dependencies.cmake:在 <code>if(BUILD_python)</code> 分支中， <code>if(NOT &quot;${python_version}&quot; VERSION_LESS &quot;3.0.0&quot;)</code> 分支中，添加：<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(<span class="keyword">NOT</span> Boost_PYTHON_FOUND)</span><br><span class="line">    <span class="keyword">find_package</span>(Boost <span class="number">1.46</span> COMPONENTS <span class="string">"python3"</span>)</span><br><span class="line">    <span class="keyword">set</span>(Boost_PYTHON_FOUND <span class="variable">$&#123;Boost_PYTHON3_FOUND&#125;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br></pre></td></tr></table></figure></p><p>然后到build文件加下，执行cmake：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo cmake -D CMAKE_BUILD_TYPE=RELEASE \</span><br><span class="line"><span class="comment"># -D BUILD_TIFF=ON -D CUDA_DIR="/usr/local/cuda-8.0" \</span></span><br><span class="line">-D CUDA_TOOLKIT_ROOT_DIR=<span class="string">"/usr/local/cuda-8.0"</span> \</span><br><span class="line">-D CUDNN_INCLUDE=<span class="string">"/usr/local/cuda-8.0/include"</span> \</span><br><span class="line">-D CUDNN_LIBRARY=<span class="string">"/usr/local/cuda-8.0/lib64/libcudnn.so"</span> \</span><br><span class="line">-D PYTHON_LIBRARIES=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/lib;/usr/local/lib"</span> \</span><br><span class="line">-D PYTHON_INCLUDE_DIR=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/include/python3.5m/"</span> \</span><br><span class="line">-D PYTHON_EXECUTABLE=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/bin/python"</span> \</span><br><span class="line">-D python_version=3.5 -D USE_NCCL=1 \</span><br><span class="line">-D NCCL_INCLUDE_DIR=<span class="string">"/home/zhengyuwei/software/nccl-master/build/include"</span> \</span><br><span class="line">-D NCCL_LIBRARIES=<span class="string">"/home/zhengyuwei/software/nccl-master/build/lib/libnccl.so"</span> ..</span><br></pre></td></tr></table></figure></p><p>Q1: 若opencv报错，没有找到opencv相关的定义。A1: 确认安装了opencv，在cmake/dependencies.cmake文件下，<code>if(USE_OPENCV)</code>行后添加一行指定opencv的安装位置：<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(USE_OPENCV)</span><br><span class="line">    <span class="keyword">set</span>(CMAKE_PREFIX_PATH /home/zhengyuwei/software/opencv/opencv-<span class="keyword">install</span> <span class="variable">$&#123;CMAKE_PREFIX_PATH&#125;</span>)</span><br></pre></td></tr></table></figure></p><p>Q2: 如果报<code>compute_image_mean.cpp:(.text.startup+0x16d): undefined reference to google::FlagRegisterer::FlagRe</code>相关的错误。A2: gflags的原因，头文件和so版本不一致，导致定义不存在。查看<code>cmake xxx ..</code>时输出的以下信息，保证路径中头文件和so一直，当然，还有glog等。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- Found GFlags: /usr/<span class="built_in">local</span>/include</span><br><span class="line">-- Found gflags  (include: /usr/<span class="built_in">local</span>/include, library: /usr/<span class="built_in">local</span>/lib/libgflags.so)</span><br></pre></td></tr></table></figure></p><p>Q3: 如果cmake失败，若是<strong>protoc报错</strong>，且确认安装protobuf且版本正确，尝试设置以下环境后，重新安装caffe：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">"/usr/local/lib:<span class="variable">$LD_LIBRARY_PATH</span>"</span></span><br><span class="line"><span class="built_in">export</span> LIBRARY_PATH=<span class="string">"/usr/local/lib:<span class="variable">$LIBRARY_PATH</span>"</span></span><br><span class="line">sudo ldconfig</span><br></pre></td></tr></table></figure></p><p>其实这是在尝试使caffe编译时，能够去获取到指定的版本。另外两个可尝试的方法是：</p><ol><li>直接在/etc/sudoers里添加protobuf的bin路径。</li><li>修改cmake/ProtoBuf.cmake，最前面加：<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_PREFIX_PATH /home/zhengyuwei/software/protobuf/protobuf-<span class="keyword">install</span>-<span class="number">2.6</span>.<span class="number">1</span> <span class="variable">$&#123;CMAKE_PREFIX_PATH&#125;</span>)</span><br><span class="line"><span class="keyword">find_package</span>( Protobuf <span class="number">2.6</span>.<span class="number">1</span> )</span><br></pre></td></tr></table></figure></li></ol><h2 id="6-安装boost-python3："><a href="#6-安装boost-python3：" class="headerlink" title="6. 安装boost-python3："></a>6. 安装boost-python3：</h2><p>若是<strong>boost-python3报错</strong>：libboost_python3.so.1.56.0: undefined symbol: PyClass_Type；则表示有人用python2编译boost产生boost-python3，而boost-python3是不需要PyClass_Type的，此时需要安装新的boost：</p><ul><li>官网下载boost代码压缩包，解压；</li><li><p>修改<code>/tools/build/src/tools/</code>路径下的<code>python.jam</code>文件中的547行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">includes ?= $(prefix)/include/python$(version) ; -&gt; includes ?= $(prefix)/include/python$(version)m ;</span><br></pre></td></tr></table></figure></li><li><p>指定python路径及版本，安装boost：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装boost-python3</span></span><br><span class="line">./bootstrap.sh --with-python=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35/bin/python3"</span> \</span><br><span class="line">--with-python-version=3.5 --with-python-root=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py35"</span> \</span><br><span class="line"> --prefix=<span class="string">"/home/zhengyuwei/software/boost_1_69_0/build"</span></span><br><span class="line">./b2 install -a --with=all </span><br><span class="line">./b2 --with-python --buildid=3</span><br><span class="line"><span class="comment"># 清理安装信息，以重新安装boost-python2</span></span><br><span class="line">./b2 --with-python --clean</span><br><span class="line">./bootstrap.sh --with-python=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27/bin/python"</span> \</span><br><span class="line">--with-python-version=2.7 --with-python-root=<span class="string">"/home/zhengyuwei/software/anaconda3/envs/caffe_py27"</span> \</span><br><span class="line">--prefix=<span class="string">"/home/zhengyuwei/software/boost_1_69_0/build"</span></span><br><span class="line"><span class="comment"># 记住把python.jam 547行改回来，不然报错</span></span><br><span class="line">./b2 --with-python --buildid=2</span><br></pre></td></tr></table></figure></li></ul><p>查看安装目录下lib，有boost-pythonX.so文件，建软连接就行了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Caffe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv3</title>
      <link href="/2018/12/15/5_YOLOv3/"/>
      <url>/2018/12/15/5_YOLOv3/</url>
      
        <content type="html"><![CDATA[<p align="center">对<strong>YOLOv3</strong>理解和复现（backbone并没用darknet53）的一点记录。</p><a id="more"></a><h3 id="改进点"><a href="#改进点" class="headerlink" title="改进点"></a>改进点</h3><p>相比YOLOv2主要改进点为：</p><ol><li><strong>多尺度</strong>：网络backbone使用FPN，融合不同粒度的学习（语义和像素信息）；detection head也分成3个尺度的feature map输出，更加适用于不同目标大小的检测；</li><li><strong>多属性</strong>：分类损失改为 二元交叉熵损失，也就是同一个目标可以属于多个类，贴近实际应用场景。</li></ol><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>原论文网络结构采用darknet-53，针对COCO数据集（80类，故每个detection head的输出为<script type="math/tex">S \times S \times (3 * (4 + 1 + 80)) = S \times S \times 255</script>）：</p><div class="table-container"><table><thead><tr><th style="text-align:right">layer</th><th style="text-align:center"></th><th style="text-align:right">filters</th><th style="text-align:right">size</th><th style="text-align:right">input</th><th style="text-align:center"></th><th style="text-align:left">output</th><th style="text-align:right"></th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:center">conv</td><td style="text-align:right">32</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">416 x 416 x 3</td><td style="text-align:center">-&gt;</td><td style="text-align:left">416 x 416 x 32</td><td style="text-align:right">0.299 BFLOPs</td></tr><tr><td style="text-align:right">1</td><td style="text-align:center">conv</td><td style="text-align:right">64</td><td style="text-align:right">3 x 3 / 2</td><td style="text-align:right">416 x 416 x 32</td><td style="text-align:center">-&gt;</td><td style="text-align:left">208 x 208 x 64</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">2</td><td style="text-align:center">conv</td><td style="text-align:right">32</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">208 x 208 x 64</td><td style="text-align:center">-&gt;</td><td style="text-align:left">208 x 208 x 32</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">3</td><td style="text-align:center">conv</td><td style="text-align:right">64</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">208 x 208 x 32</td><td style="text-align:center">-&gt;</td><td style="text-align:left">208 x 208 x 64</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">4</td><td style="text-align:center">res</td><td style="text-align:right">1</td><td style="text-align:right"></td><td style="text-align:right">208 x 208 x 64</td><td style="text-align:center">-&gt;</td><td style="text-align:left">208 x 208 x 64</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">5</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">3 x 3 / 2</td><td style="text-align:right">208 x 208 x 64</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 128</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">6</td><td style="text-align:center">conv</td><td style="text-align:right">64</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">104 x 104 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 64</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">7</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">104 x 104 x 64</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 128</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">8</td><td style="text-align:center">res</td><td style="text-align:right">5</td><td style="text-align:right"></td><td style="text-align:right">104 x 104 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 128</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">9</td><td style="text-align:center">conv</td><td style="text-align:right">64</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">104 x 104 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 64</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">10</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">104 x 104 x 64</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 128</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">11</td><td style="text-align:center">res</td><td style="text-align:right">8</td><td style="text-align:right"></td><td style="text-align:right">104 x 104 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">104 x 104 x 128</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">12</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 2</td><td style="text-align:right">104 x 104 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">13</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">14</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">15</td><td style="text-align:center">res</td><td style="text-align:right">12</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">16</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">17</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">18</td><td style="text-align:center">res</td><td style="text-align:right">15</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">19</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">20</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">21</td><td style="text-align:center">res</td><td style="text-align:right">18</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">22</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">23</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">24</td><td style="text-align:center">res</td><td style="text-align:right">21</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">25</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">26</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">27</td><td style="text-align:center">res</td><td style="text-align:right">24</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">28</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">29</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">30</td><td style="text-align:center">res</td><td style="text-align:right">27</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">31</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">32</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">33</td><td style="text-align:center">res</td><td style="text-align:right">30</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">34</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">35</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">$\color{SpringGreen}{36}$</td><td style="text-align:center">res</td><td style="text-align:right">33</td><td style="text-align:right"></td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">37</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 2</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">38</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">39</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">40</td><td style="text-align:center">res</td><td style="text-align:right">37</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">41</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">42</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">43</td><td style="text-align:center">res</td><td style="text-align:right">40</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">44</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">45</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">46</td><td style="text-align:center">res</td><td style="text-align:right">43</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">47</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">48</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">49</td><td style="text-align:center">res</td><td style="text-align:right">46</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">50</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">51</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">52</td><td style="text-align:center">res</td><td style="text-align:right">49</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">53</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">54</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">55</td><td style="text-align:center">res</td><td style="text-align:right">52</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">56</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">57</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">58</td><td style="text-align:center">res</td><td style="text-align:right">55</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">59</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">60</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">$\color{blue}{61}$</td><td style="text-align:center">res</td><td style="text-align:right">58</td><td style="text-align:right"></td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">62</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 2</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">63</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">64</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">65</td><td style="text-align:center">res</td><td style="text-align:right">62</td><td style="text-align:right"></td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">66</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">67</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">68</td><td style="text-align:center">res</td><td style="text-align:right">65</td><td style="text-align:right"></td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">69</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">70</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">71</td><td style="text-align:center">res</td><td style="text-align:right">68</td><td style="text-align:right"></td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">72</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">73</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">74</td><td style="text-align:center">res</td><td style="text-align:right">71</td><td style="text-align:right"></td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">75</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">76</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">77</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">78</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">$\color{blue}{79}$</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 512</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">80</td><td style="text-align:center">conv</td><td style="text-align:right">1024</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 1024</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">81</td><td style="text-align:center">conv</td><td style="text-align:right">255</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 1024</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 255</td><td style="text-align:right">0.026 BFLOPs</td></tr><tr><td style="text-align:right">82</td><td style="text-align:center">$\color{red}{detection}$</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">83</td><td style="text-align:center">route</td><td style="text-align:right">$\color{blue}{79}$</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">84</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">13 x 13 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">13 x 13 x 256</td><td style="text-align:right">0.044 BFLOPs</td></tr><tr><td style="text-align:right">85</td><td style="text-align:center">upsample</td><td style="text-align:right"></td><td style="text-align:right">2x</td><td style="text-align:right">13 x 13 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">86</td><td style="text-align:center">route</td><td style="text-align:right">85</td><td style="text-align:right">$\color{blue}{61}$</td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">87</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 768</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.266 BFLOPs</td></tr><tr><td style="text-align:right">88</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">89</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">90</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">$\color{SpringGreen}{91}$</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 256</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">92</td><td style="text-align:center">conv</td><td style="text-align:right">512</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 512</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">93</td><td style="text-align:center">conv</td><td style="text-align:right">255</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 512</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 255</td><td style="text-align:right">0.052 BFLOPs</td></tr><tr><td style="text-align:right">94</td><td style="text-align:center">$\color{red}{detection}$</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">95</td><td style="text-align:center">route</td><td style="text-align:right">$\color{SpringGreen}{91}$</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">96</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">26 x 26 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">26 x 26 x 128</td><td style="text-align:right">0.044 BFLOPs</td></tr><tr><td style="text-align:right">97</td><td style="text-align:center">upsample</td><td style="text-align:right"></td><td style="text-align:right">2x</td><td style="text-align:right">26 x 26 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">98</td><td style="text-align:center">route</td><td style="text-align:right">97</td><td style="text-align:right">$\color{SpringGreen}{36}$</td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">99</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 384</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.266 BFLOPs</td></tr><tr><td style="text-align:right">100</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">101</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">102</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">103</td><td style="text-align:center">conv</td><td style="text-align:right">128</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 128</td><td style="text-align:right">0.177 BFLOPs</td></tr><tr><td style="text-align:right">104</td><td style="text-align:center">conv</td><td style="text-align:right">256</td><td style="text-align:right">3 x 3 / 1</td><td style="text-align:right">52 x 52 x 128</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 256</td><td style="text-align:right">1.595 BFLOPs</td></tr><tr><td style="text-align:right">105</td><td style="text-align:center">conv</td><td style="text-align:right">255</td><td style="text-align:right">1 x 1 / 1</td><td style="text-align:right">52 x 52 x 256</td><td style="text-align:center">-&gt;</td><td style="text-align:left">52 x 52 x 255</td><td style="text-align:right">0.104 BFLOPs</td></tr><tr><td style="text-align:right">106</td><td style="text-align:center">$\color{red}{detection}$</td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:right"></td><td style="text-align:center"></td><td style="text-align:left"></td><td style="text-align:right"></td></tr></tbody></table></div><h3 id="多尺度"><a href="#多尺度" class="headerlink" title="多尺度"></a>多尺度</h3><p align="center">    <img src="/images/YOLOv3/FPN.png"></p><blockquote><p>骨干结构参考了FPN结构</p></blockquote><p>YOLOv3采用多个尺度进行预测（之所以从小到大解释，因为大尺度依赖小尺度的上采样）：</p><ul><li><p>小尺度：<script type="math/tex">13 \times 13</script>，网络接受<script type="math/tex">416 \times 416 \times 3</script>的图，经过5个步长为2的卷积模块，得到第79层<script type="math/tex">13(=\frac{416}{2^{5}}) \times 13 \times 512</script>特征图，然后接上两层卷积以进行检测回归，最终得到输出特征图 <script type="math/tex">13 \times 13 \times 255</script>；</p></li><li><p>中尺度：<script type="math/tex">26 \times 26</script>，顺着主骨干网络第79层<script type="math/tex">13 \times 13 \times 512</script>，用<script type="math/tex">1 \times 1 \times 256</script>卷积核将channel减半，然后上采样<script type="math/tex">\times 2</script>得到<script type="math/tex">26 \times 26 \times 256</script>；取主骨干网络的第61层<script type="math/tex">26 \times 26 \times 512</script>分支concat起来，得到<script type="math/tex">26 \times 26 \times 768</script>特征图，然后接上7层卷积以进行检测回归，最终得到输出特征图 <script type="math/tex">26 \times 26 \times 255</script>；</p></li><li><p>大尺度：<script type="math/tex">52 \times 52</script>，顺着中尺度的detection head第91层<script type="math/tex">26 \times 26 \times 256</script>，用<script type="math/tex">1 \times 1 \times 128</script>卷积核将channel减半，然后上采样<script type="math/tex">\times 2</script>得到<script type="math/tex">52 \times 52 \times 128</script>；取主骨干网络的第36层<script type="math/tex">26 \times 26 \times 256</script>分支concat起来，得到<script type="math/tex">26 \times 26 \times 384</script>特征图，然后接上7层卷积以进行检测回归，最终得到输出特征图 <script type="math/tex">52 \times 52 \times 255</script>；</p></li></ul><p>对应的，通过聚类而得到的anchor box，也要分配到三个尺度的检测分支去：将尺度大的anchor分配到感受野大的（也就是下采样stride大的检测分支），将尺度小的anchor分配到感受野小的（也就是下采样stride小的检测分支）。</p><p>另外，训练的时候也用了多尺度的输入进行实验。</p><h3 id="多属性"><a href="#多属性" class="headerlink" title="多属性"></a>多属性</h3><p>YOLOv3损失函数与YOLOv2损失函数是一致的，唯一的区别是分类误差部分，需要修改为：</p><script type="math/tex; mode=display">L_{class} = \sum_{i=0}^{S^2} I_{ij}^{obj} \sum_{c}^{classes} (p_{i}(c)-\hat{p}_{i}(c))^2</script><p>也就是说，由于分类概率的预测改为每个类都是二元交叉熵预测，分类损失需要对所有类别都添加损失项，而不像YOLOv2 softmax那种计算方式。</p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p>后续放出来。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://github.com/qqwweee/keras-yolo3" target="_blank" rel="noopener">qqwweee/keras-yolo3</a></p><p><a href="https://www.cnblogs.com/makefile/p/YOLOv3.html" target="_blank" rel="noopener">目标检测网络之 YOLOv3</a></p><p><a href="https://blog.csdn.net/v_july_v/article/details/80170182" target="_blank" rel="noopener">一文读懂目标检测：R-CNN、Fast R-CNN、Faster R-CNN、YOLO、SSD</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
            <tag> YOLO系列 </tag>
            
            <tag> anchor-based </tag>
            
            <tag> one-stage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv2</title>
      <link href="/2018/10/03/4_YOLOv2/"/>
      <url>/2018/10/03/4_YOLOv2/</url>
      
        <content type="html"><![CDATA[<p align="center">对<strong>YOLOv2</strong>理解和复现（backbone并没用darknet19）的一点记录。</p><a id="more"></a><p align="center">    <img src="/images/YOLOv2/yolov2.png"></p><blockquote><p>YOLOv2将检测作为一个分类+回归问题：将图片分割为<script type="math/tex">S×S</script>个grid，每一个grid单元预测<script type="math/tex">B</script>个bounding box、置信度、<script type="math/tex">C</script>个类别概率，这些会被编码为一个<script type="math/tex">S \times S \times (B * (4+1+C))</script>的矩阵。</p></blockquote><h3 id="YOLOv2整体网络"><a href="#YOLOv2整体网络" class="headerlink" title="YOLOv2整体网络"></a>YOLOv2整体网络</h3><p>主要可分为以下三个方面：</p><ol><li><p>backbone为全卷积网络FCN，整体网络降采样32倍，有利于多尺度训练（Multi-Scale Training）；</p></li><li><p>使用leaky ReLU作为激活函数：</p><script type="math/tex; mode=display">\Theta (x)=\left\{\begin{matrix}x & if\; x > 0\\0.1x & otherwise\end{matrix}\right.</script></li><li><p>输出解码：backbone输出为<script type="math/tex">13 \times 13 \times (B*(4+1+C))</script>的三维矩阵。其中：</p><ul><li><p>超参数<script type="math/tex">B</script>：每个grid的bounding boxes的数量；</p></li><li><p>类别数<script type="math/tex">C</script>（不包含背景，所有单类的话这个分支可以去掉，损失函数部分也对应去掉），每位数对应相应类别的概率预测<script type="math/tex">Pr(Class_{i}|Object)</script>（之所以要定义为<code>Object</code>的条件概率，是因为总损失函数里，只有当<code>Object</code>中心落到对应的grid中时，该grid才计算分类损失），故该类别预测向量<script type="math/tex">\overrightarrow{z}</script>可以通过softmax函数转化为[0,1]之间类别概率：</p><script type="math/tex; mode=display">Pr(Class_{i}|Object)=\frac{e^{z_{i}}}{\sum_{j}^{C}e^{z_{j}}}</script><p>实现上，为了防止数值溢出，一般会减去最大值的操作<script type="math/tex">\overrightarrow{z}-max_{i}(z_{i})</script>。</p></li><li><p>4个bounding box对应的坐标信息：中心点及宽高<script type="math/tex">(x_{center}, y_{center}, w, h)</script>,考虑到模型训练过程的稳定性，不能像region proposal算法那样，不约束预测中心的位置：</p><script type="math/tex; mode=display">\begin{eqnarray}& x = & (t_{a} * w_{a}) + x_{a} \\& y = & (t_{a} * h_{a}) + y_{a}\end{eqnarray}</script><p>并且YOLO把物体的检测任务根据物品中心分配到对应的grid去，所以理应把预测中心的位置限制在当前grid中，故提出了中心坐标<script type="math/tex">(b_{x}, b{y})</script>根据grid的左上角坐标<script type="math/tex">(c_{x}, c_{y})</script>的偏移进行预测，宽高的预测则是基于anchors进行比例伸缩：</p><script type="math/tex; mode=display">\begin{eqnarray}& b_{x} = & \sigma(t_{x}) + c_{x} \\& b_{y} = & \sigma(t_{y}) + c_{y} \\& b_{w} = & p_{w}e^{t_{w}} \\& b_{h} = & p_{h}e^{t_{h}}\end{eqnarray}</script></li><li><p>1个IOU预测值：<script type="math/tex">Pr(Object) * IOU_{pred}^{truth}</script>，这里<script type="math/tex">Pr(Object)</script>指：只有当<code>Object</code>中心落到对应的grid中时，该grid才计算该预测值与实际IOU的损失，否则计算该预测值与0的损失。此时，预测值也约束为[0,1]之间：</p><script type="math/tex; mode=display">Pr(Object) * IOU_{pred}^{truth} = \sigma(t_{o})</script></li></ul></li></ol><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>YOLO系列的精髓在于他的思想简单直接，使用的技巧也很纯粹。其中的损失函数部分，更是YOLO系列理解和实现中最重要的部分：</p><script type="math/tex; mode=display">\begin{matrix}L = \lambda_{coord}*(L_{xy} + L_{wh}) + L_{iou}^{obj} + \lambda_{noobj}*L_{iou}^{noobj} + L_{class} \\\begin{eqnarray}& L_{xy} = & \sum_{i=0}^{S^2} \sum_{j=0}^{B} I_{ij}^{obj}[(x_{i}-\hat{x}_{i})^2 + (y_{i}-\hat{y}_{i})^2] \\& L_{wh} = & \sum_{i=0}^{S^2} \sum_{j=0}^{B} I_{ij}^{obj}[(\sqrt{w_{i}}-\sqrt{\hat{w}_{i}})^2 + (\sqrt{h_{i}}-\sqrt{\hat{h}_{i}})^2] \\& L_{iou}^{obj} = & \sum_{i=0}^{S^2} \sum_{j=0}^{B} I_{ij}^{obj}(C_{i}-\hat{C}_{i})^2 \\& L_{iou}^{noobj} = & \sum_{i=0}^{S^2} \sum_{j=0}^{B} I_{ij}^{noobj}(C_{i}-\hat{C}_{i})^2 \\& L_{class} = & \sum_{i=0}^{S^2} I_{ij}^{obj} \sum_{c=class} (p_{i}(c)-\hat{p}_{i}(c))^2\end{eqnarray}\end{matrix}</script><p>上面的公式，比较难理解的地方在于：<script type="math/tex">I_{ij}^{obj}</script>和<script type="math/tex">I_{ij}^{noobj}</script>的规定、<script type="math/tex">\lambda_{...}</script>这些系数的选取。</p><p>我们以输出矩阵为<script type="math/tex">7 \times 7 \times (5*(4+1+10))</script>的情况进行举例讲解：</p><ul><li><strong><script type="math/tex">I_{ij}^{obj}</script>的解释</strong>：如下图所示，原图<script type="math/tex">224 \times 224</script>的输入，经过<script type="math/tex">32</script>倍的下采样，得到<script type="math/tex">7 \times 7</script>的输出。YOLO系列算法中，将目标物体的检测任务，分配到输出层的对应grid中：原图目标检测框的中心点位置，落在<script type="math/tex">7 \times 7</script>的输出特征图中的第<script type="math/tex">i</script>个grid中，而这个grid的第<script type="math/tex">j</script>个anchor预测框与真实框的IOU最大，故第<script type="math/tex">i</script>个grid的第<script type="math/tex">j</script>个anchor预测框负责该物体的检测。也就是，<strong>目标物体中心点所在的grid中，<script type="math/tex">5</script>个候选框中与目标框IOU最大的预测框，才用来预测该目标候选框：此grid、此anchor对应公式中<script type="math/tex">I_{ij}^{obj}=1</script>的情况，其他情况<script type="math/tex">I_{ij}^{obj}=0</script></strong>。</li></ul><p align="center">    <img src="/images/YOLOv2/yolo_grid.png"></p><blockquote><p>这个图来自<a href="https://www.cnblogs.com/makefile/p/YOLOv3.html" target="_blank" rel="noopener">目标检测网络之 YOLOv3</a>，</p></blockquote><ul><li><p><strong><script type="math/tex">I_{ij}^{noobj}</script>的解释</strong>：上面解释了<script type="math/tex">I_{ij}^{obj}</script>的情况，并<strong>不是<script type="math/tex">I_{ij}^{obj}=0</script>就是<script type="math/tex">I_{ij}^{noobj}=1</script></strong>，<strong>只有预测框与所有的真实目标框的IOU都小于一定阈值（<a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolo9000.cfg" target="_blank" rel="noopener">darknet YOLO9000</a> thresh是0.6,<a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg" target="_blank" rel="noopener">darknet YOLOv3</a> ignore thresh 是0.7），才是<script type="math/tex">I_{ij}^{noobj}=1</script>的情况</strong>，此时我们才认为该grid、该anchor的预测框没有任何目标存在，为background区域，需要计算背景IOU损失！而大于这个阈值而又不是<script type="math/tex">I_{ij}^{obj}=1</script>的anchor，是不用计算损失的。</p></li><li><p>没有目标存在的grid、anchor，需要使其预测IOU趋于0，也就是<script type="math/tex">L_{iou}^{noobj}</script>损失部分，而有目标的grid、anchor，则需要其预测的IOU趋于1、预测的物品类别概率正确、预测框位置准确，也就是对应的<script type="math/tex">L_{iou}^{obj}</script>、<script type="math/tex">L_{class}</script>、<script type="math/tex">(L_{xy} + L_{wh})</script>损失部分。作者认为，背景区域比较多，所以背景区域带来的IOU损失权重应该比较小：<script type="math/tex">\lambda_{noobj}=0.5</script>；而目标区域的位置误差只有4维，而物品类别误差有20/80维，那么<script type="math/tex">\lambda_{coord}=5</script>设置大一些。（这是可以调参的部分；同时，复现的人会将focal loss用在IOU的损失函数这块上，因为只有这块有背景和前景的失衡情况）</p></li><li><p>损失函数里对宽高进行了开方，是为了缓和大小不同的box预测时的偏移差异：相比于大bbox预测偏一点，小box预测偏一点更不能忍受（这里用相对尺度<script type="math/tex">1-\frac{\hat{w}}{w}</script>会不会更好一些？）。</p></li></ul><p><strong>重要的额外说明</strong>：</p><p> 实际实现中，为了使前期训练（前12800张训练图片）时，位置的回归具有一定的稳定性，加入了额外的损失项，可参考下文。</p><p align="center">    <img src="/images/YOLOv2/yolov1_loss.jpg"></p><blockquote><p>这个图来自<a href="https://zhuanlan.zhihu.com/p/24916786" target="_blank" rel="noopener">图解YOLO</a>，虽然针对YOLO，但是可以参考一下。</p></blockquote><p align="center">    <img src="/images/YOLOv2/yolov1_2.png"></p><blockquote><p>这个图来自<a href="https://zhuanlan.zhihu.com/p/25167153" target="_blank" rel="noopener">YOLO2</a>，实际YOLOv2的论文中，先验box为5个。</p></blockquote><h3 id="YOLOv2的训练与测试"><a href="#YOLOv2的训练与测试" class="headerlink" title="YOLOv2的训练与测试"></a>YOLOv2的训练与测试</h3><p><strong>训练</strong>：</p><ol><li>先用ImageNet 224*224进行分类预训练backbone；</li><li>再用ImageNet 448*448进行fine-tuning训练backbone；</li><li>最后切换为检测任务，fine-tuning整体模型；</li><li>前期12800张图片的损失函数，增加损失项：<script type="math/tex; mode=display">\begin{matrix}L = \lambda_{prior}*L_{xy} + \lambda_{prior}*L_{wh} \\\begin{eqnarray}& L_{xy} = & \sum_{i=0}^{S^2} \sum_{j=0}^{B} [(x_{i}-\hat{x}_{i})^2 + (y_{i}-\hat{y}_{i})^2] \\& L_{wh} = & \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^{B} [(\sqrt{w_{i}}-\sqrt{\hat{w}_{i}})^2 + (\sqrt{h_{i}}-\sqrt{\hat{h}_{i}})^2] \\\end{eqnarray}\end{matrix}</script>其中，<script type="math/tex">(x_{i}, y_{i}, w_{i}, h_{i})</script>是预测框<script type="math/tex">(\hat{x}_{i}, \hat{y}_{i}, \hat{w}_{i}, \hat{h}_{i})</script>的先验框，<script type="math/tex">(x_{i}, y_{i})</script>是中心点；以此来使得前期所有的预测框往先验框大小靠近，往grid中心点移动。<strong>稳定前期训练，且有利于后期预测框的学习（预测位置在0.5左右，刚好是sigmoid梯度最大的地方）</strong>。</li></ol><p><strong>测试</strong>：</p><ol><li>测试时，计算指定类别的置信度：<script type="math/tex; mode=display">Pr(Class_{i}|Object) * Pr(Object) * IOU_{pred}^{truth} = Pr(Class_{i}) * IOU_{pred}^{truth}</script>大于一定阈值的话，则认为检测到目标<script type="math/tex">Class_{i}</script>。</li><li>对所有grid进行如上计算及阈值过滤，然后进行NMS，得到最终检测结果。</li></ol><h3 id="YOLOv2周边"><a href="#YOLOv2周边" class="headerlink" title="YOLOv2周边"></a>YOLOv2周边</h3><p>包含聚类anchors、YOLOv2的局限、单类检测的讨论。</p><h4 id="聚类anchors"><a href="#聚类anchors" class="headerlink" title="聚类anchors"></a>聚类anchors</h4><p>用k-means（每张图片的所有目标的<code>(W, H)</code>作为输入特征，目标框与聚类中心的<script type="math/tex">d(box, centroid) = 1-IOU(box, centroid)</script>作为距离评价指标）进行聚类，以k个聚类中心的尺寸<code>(W, H)</code>作为网络预定义的k个anchors的尺寸。</p><h4 id="YOLOv2的局限"><a href="#YOLOv2的局限" class="headerlink" title="YOLOv2的局限"></a>YOLOv2的局限</h4><p>最终检测的特征图相对原图的缩放倍数为32倍，不利于小物体检测，在YOLOv3用 FPN + 基于resize的上采样信息融合 + 3种下采样率的分支 改进。</p><h4 id="单类检测"><a href="#单类检测" class="headerlink" title="单类检测"></a>单类检测</h4><p>如果是单类检测器，也就是说其实这时只是为了定位，以提供后续处理，那么可以删除网络中的分类预测channel（单类也就是1个channel），然后损失函数里也不需要<script type="math/tex">L_{class}</script>分支。</p><h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><a href="https://github.com/zheng-yuwei/YOLOv2-tensorflow" target="_blank" rel="noopener">zheng-yuwei/YOLOv2-tensorflow</a></p><p>基于tensorflow keras实现，包含中文注释讲解。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://zhuanlan.zhihu.com/p/24916786" target="_blank" rel="noopener">图解YOLO</a></p><p><a href="https://zhuanlan.zhihu.com/p/25167153" target="_blank" rel="noopener">YOLO2</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
            <tag> YOLO系列 </tag>
            
            <tag> anchor-based </tag>
            
            <tag> one-stage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于SVD++的协同过滤</title>
      <link href="/2018/07/23/3_%E5%9F%BA%E4%BA%8ESVD++%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movilens-1m/"/>
      <url>/2018/07/23/3_%E5%9F%BA%E4%BA%8ESVD++%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movilens-1m/</url>
      
        <content type="html"><![CDATA[<p align="center">对<strong>基于SVD++的协同过滤</strong>理解和复现的一点记录。</p><a id="more"></a><h3 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h3><ul><li>日志对象；</li><li>读取数据/分割数据集；</li><li>创建SVD++模型对象/初始化参数；</li><li>训练SVD++模型；</li><li>预测评分并评估模型。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> logger <span class="keyword">import</span> Logger</span><br><span class="line"><span class="keyword">from</span> movielens <span class="keyword">import</span> RatingData</span><br><span class="line"><span class="keyword">from</span> svdPlusPlus <span class="keyword">import</span> SVDPlusPlus</span><br><span class="line"><span class="keyword">import</span> winsound</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取日志对象</span></span><br><span class="line">logPath = os.path.join(<span class="string">'logs'</span>, <span class="string">'svdPP.log'</span>)</span><br><span class="line">logger = Logger.getLogger(logPath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">filepath = os.path.join(<span class="string">'ml-1m'</span>, <span class="string">'ratings.dat'</span>)</span><br><span class="line"><span class="comment">#dataset = RatingData.getSmallRatingData(logger, filepath, 0.7, 0.3, False)</span></span><br><span class="line">dataset = RatingData.getRatingDict(logger, filepath, <span class="number">0.9</span>, <span class="literal">True</span>)</span><br><span class="line">trainset = dataset[RatingData.TRAIN_SET_KEY]</span><br><span class="line">testset = dataset[RatingData.TEST_SET_KEY]</span><br><span class="line">historyset = trainset</span><br><span class="line">topicNum = <span class="number">8</span></span><br><span class="line">lr = <span class="number">0.0006</span></span><br><span class="line">gamma = <span class="number">0.03</span></span><br><span class="line">svdPlusPlus = SVDPlusPlus(logger, trainset, historyset, topicNum, lr, gamma)</span><br><span class="line">svdPlusPlus.train(<span class="number">100</span>, topN=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#svd预测</span></span><br><span class="line">svdPlusPlus.evaluate(testset, topN=<span class="number">10</span>)</span><br><span class="line">winsound.Beep(<span class="number">500</span>, <span class="number">500</span>)</span><br></pre></td></tr></table></figure><h3 id="SVD-模块"><a href="#SVD-模块" class="headerlink" title="SVD++模块"></a>SVD++模块</h3><p>其他模块与SVD中的同名模块一致，只有svd模块改为svdPlusPlus模块（SVDPlusPlus类继承SVD类，++指加入了隐反馈信息（用户浏览、点击等反馈信息），我这里没有，故暂且把训练集也当做隐反馈信息，命名为历史数据集historyset）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> svd <span class="keyword">import</span> SVD</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVDPlusPlus</span><span class="params">(SVD)</span>:</span></span><br><span class="line">    <span class="string">''' 基于SVD++的协同过滤算法 '''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, logger, trainset, historyset, topicNum, lr, gamma)</span>:</span></span><br><span class="line">        <span class="string">''' 初始化函数</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">            trainset:训练集</span></span><br><span class="line"><span class="string">            historyset:历史数据集</span></span><br><span class="line"><span class="string">            topicNum:主题个数，奇异值数量</span></span><br><span class="line"><span class="string">            lr:学习率</span></span><br><span class="line"><span class="string">            gamma:正则项权重</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.historyset = historyset</span><br><span class="line">        self.yItem = &#123;&#125;</span><br><span class="line">        super().__init__(logger, trainset, topicNum, lr, gamma)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initModel</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">''' 初始化模型参数：biasUser、biasItem、pUser、qItem、yItem '''</span></span><br><span class="line">        super().initModel()</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> self.biasItem.keys():</span><br><span class="line">            self.yItem[item] = np.random.rand(self.topicNum) / <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, iteration, topN)</span>:</span></span><br><span class="line">        <span class="string">''' 迭代多批次训练SVD模型</span></span><br><span class="line"><span class="string">        min power(rated - rate, 2)/2 + gamma * regularization/2</span></span><br><span class="line"><span class="string">        rate = mean + biasUser + biasItem + qItem * (pUser + yItemUserSum/sqrt(itemCounter))</span></span><br><span class="line"><span class="string">        itemCounter = sqrt(len(self.historyset[user].keys()))</span></span><br><span class="line"><span class="string">        yItemUserSum = sum(map(lambda key:self.yItem[key], self.historyset[user].keys()))</span></span><br><span class="line"><span class="string">        regularization = power(biasUser) + power(biasItem) + power(pUser) + power(qItem) + power(yItem)</span></span><br><span class="line"><span class="string">        故每次迭代：lr = learning rate</span></span><br><span class="line"><span class="string">        delta(biasUser) = lr * ((rate - rated) + gamma * biasUser)</span></span><br><span class="line"><span class="string">        delta(biasItem) = lr * ((rate - rated) + gamma * biasItem)</span></span><br><span class="line"><span class="string">        delta(qItem) = lr * ((rate - rated) * (pUser + yItemUserSum/itemCounter) + gamma * qItem)</span></span><br><span class="line"><span class="string">        delta(pUser) = lr * ((rate - rated) * qItem + gamma * pUser)</span></span><br><span class="line"><span class="string">        delta(yItem) = lr * (rate - rated) * qItem/itemCounter + gamma * yItem)</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            iteration:迭代次数</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.logger.info(<span class="string">'开始训练...'</span>)</span><br><span class="line">        sampleSize = len(self.trainMap)     <span class="comment"># 训练样本总数</span></span><br><span class="line">        sampleSeq = np.arange(sampleSize)    <span class="comment"># 训练样本号的训练队列</span></span><br><span class="line">        <span class="comment"># 迭代训练</span></span><br><span class="line">        self.logger.info(<span class="string">'训练前，误差为：'</span>)</span><br><span class="line">        self.evaluate(self.trainset, topN)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(iteration):</span><br><span class="line">            np.random.shuffle(sampleSeq)    <span class="comment"># 打乱训练样本号的训练队列</span></span><br><span class="line">            <span class="comment"># 取样本号，逐样本训练</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> sampleSeq:</span><br><span class="line">                user, item = self.trainMap[j]</span><br><span class="line">                rate = self.predict(user, item)     <span class="comment"># 预测得分，计算差异</span></span><br><span class="line">                rated = self.trainset[user][item]</span><br><span class="line">                itemCounter = np.sqrt(len(self.historyset[user].keys()))</span><br><span class="line">                yItemUserSum = sum(map(<span class="keyword">lambda</span> key:self.yItem[key], self.historyset[user].keys()))</span><br><span class="line">                <span class="comment"># 计算预测误差，并更新参数</span></span><br><span class="line">                rateDiff = rate - rated</span><br><span class="line">                self.biasUser[user] -= (self.lr * (rateDiff + self.gamma * self.biasUser[user]))</span><br><span class="line">                self.biasItem[item] -= (self.lr * (rateDiff + self.gamma * self.biasItem[item]))</span><br><span class="line">                self.qItem[item] -= (self.lr * (rateDiff * (self.pUser[user] + yItemUserSum/itemCounter) +</span><br><span class="line">                          self.gamma * self.qItem[item]))</span><br><span class="line">                self.pUser[user] -= (self.lr * (rateDiff * self.qItem[item] +</span><br><span class="line">                          self.gamma * self.pUser[user]))</span><br><span class="line">                <span class="comment"># 针对该用户的历史评分物品，更新物品被浏览时，获得的偏好向量</span></span><br><span class="line">                <span class="keyword">for</span> historyItem <span class="keyword">in</span> self.historyset[user].keys():</span><br><span class="line">                    self.yItem[historyItem] -= (self.lr * (rateDiff * self.qItem[item]/itemCounter +</span><br><span class="line">                              self.gamma * self.yItem[historyItem]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                self.logger.info(<span class="string">'训练进度[&#123;i&#125;/&#123;iteration&#125;]，训练误差为：'</span>.format(i=i,</span><br><span class="line">                                 iteration=iteration))</span><br><span class="line">                self.evaluate(self.trainset, topN)</span><br><span class="line">                self.lr *= <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'训练后，误差为：'</span>)</span><br><span class="line">        self.evaluate(self.trainset, topN)</span><br><span class="line">        self.logger.info(<span class="string">'训练结束！'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, user, item)</span>:</span></span><br><span class="line">        <span class="string">''' 测试SVD模型</span></span><br><span class="line"><span class="string">        rate = mean + biasUser + biasItem + qItem * (pUser + yItemUserSum/itemCounter)</span></span><br><span class="line"><span class="string">        itemCounter = sqrt(len(self.historyset[user].keys()))</span></span><br><span class="line"><span class="string">        yItemUserSum = sum(map(lambda key:self.yItem[key], self.historyset[user].keys()))</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user:待预测评分的用户</span></span><br><span class="line"><span class="string">            item:待预测评分的物品</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            rate:用户user对物品item的评分</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        itemCounter = np.sqrt(len(self.historyset[user].keys()))</span><br><span class="line">        yItemUserSum = sum(map(<span class="keyword">lambda</span> key:self.yItem[key], self.historyset[user].keys()))</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rate = (self.mean + self.biasUser[user] + self.biasItem[item] +</span><br><span class="line">                    np.dot(self.qItem[item], self.pUser[user] + yItemUserSum/itemCounter))</span><br><span class="line">        <span class="keyword">except</span> ZeroDivisionError <span class="keyword">as</span> e:</span><br><span class="line">            traceback.print_exc()</span><br><span class="line">            print(user)</span><br><span class="line">            print(itemCounter)</span><br><span class="line">            <span class="keyword">raise</span> e</span><br><span class="line">        <span class="keyword">return</span> rate</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h4 id="SVD与SVD-速度对比"><a href="#SVD与SVD-速度对比" class="headerlink" title="SVD与SVD++速度对比"></a>SVD与SVD++速度对比</h4><p>先简单对比评分估计的的公式的计算时间复杂度：</p><p><strong>SVD</strong>： <script type="math/tex">y = \mu + \beta_{userBias} + \beta_{itemBias} + q_{item} * p_{user}</script>；</p><p><strong>SVD++</strong>:  <script type="math/tex">y = \mu + \beta_{userBias} + \beta_{itemBias} + q_{item} * (p_{user} + \frac{1}{UserInterestItem} * \sum_{i \in UserInterestItem}(y_{item}[i]))</script>，其中<script type="math/tex">UserInterestItem</script>为用户感兴趣的历史物品。</p><p>对单个用户单个物品而言，忽略前三项的计算时间复杂度，同时，加上乘法的时间复杂度是加法的10倍，那么SVD的时间复杂度主要是<script type="math/tex">q_{item} * p_{user}</script>的计算，大概是<code>O(11*topicNum）</code>；SVD++则是<script type="math/tex">q_{item} * (p_{user} + \frac{1}{UserInterestItem} * \sum_{i \in UserInterestItem}(y_{item}[i]))</script>的计算，大概是：<code>O(11*topicNum）+O(topicNum)+O(counter*topicNum）+O(10*topicNum)</code>，其中<script type="math/tex">counter=稀疏度*item种类数=0.03*3000+=100+</script>。</p><p>综上，SVD++的计算时间复杂度可粗略估计为SVD的10倍以上。但可以通过离线计算得到模型，降低时间复杂度的影响。</p><h4 id="对偶算法"><a href="#对偶算法" class="headerlink" title="对偶算法"></a>对偶算法</h4><p>通过数据集的转置，实现对偶算法的实现。通过两者的结合，可提高精度。然而，其实推荐更多考虑的top N推荐的准确度，对于RMSE的精度，并不是多care。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 协同过滤 </tag>
            
            <tag> 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于SVD的协同过滤</title>
      <link href="/2018/07/19/2_%E5%9F%BA%E4%BA%8ESVD%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movielens-1m/"/>
      <url>/2018/07/19/2_%E5%9F%BA%E4%BA%8ESVD%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movielens-1m/</url>
      
        <content type="html"><![CDATA[<p align="center">对<strong>基于SVD的协同过滤</strong>理解和复现的一点记录。</p><a id="more"></a><h3 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h3><ul><li>日志对象；</li><li>读取数据/分割数据集；</li><li>创建SVD模型对象/初始化参数；</li><li>训练SVD模型；</li><li>预测评分并评估模型。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> logger <span class="keyword">import</span> Logger</span><br><span class="line"><span class="keyword">from</span> movielens <span class="keyword">import</span> RatingData</span><br><span class="line"><span class="keyword">from</span> svd <span class="keyword">import</span> SVD</span><br><span class="line"><span class="keyword">import</span> winsound</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#%% svd协同过滤</span></span><br><span class="line"><span class="comment"># 获取日志对象</span></span><br><span class="line">timeMarker = time.strftime(<span class="string">'%m%d%H%M'</span>, time.localtime())</span><br><span class="line">logPath = os.path.join(<span class="string">'logs'</span>, <span class="string">'svd'</span> + timeMarker + <span class="string">'.log'</span>)</span><br><span class="line">logger = Logger.getLogger(logPath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据集</span></span><br><span class="line">filepath = os.path.join(<span class="string">'ml-1m'</span>, <span class="string">'ratings.dat'</span>)</span><br><span class="line"><span class="comment">#dataset = RatingData.getRatingDict(logger, filepath, 0.7, False)</span></span><br><span class="line"><span class="comment">#dataset = RatingData.getRatingDict(logger, filepath, 0.9, True)</span></span><br><span class="line">dataset = RatingData.getSmallRatingData(logger, filepath, <span class="number">0.7</span>, <span class="number">0.3</span>, <span class="literal">False</span>)</span><br><span class="line"><span class="comment">#dataset = RatingData.getSmallRatingData(logger, filepath, 0.7, 0.3, True)</span></span><br><span class="line">trainset = dataset[RatingData.TRAIN_SET_KEY]</span><br><span class="line">testset = dataset[RatingData.TEST_SET_KEY]</span><br><span class="line"></span><br><span class="line"><span class="comment">#svd训练</span></span><br><span class="line">topicNum = <span class="number">8</span></span><br><span class="line">svdModel = SVD(logger, trainset, topicNum, lr=<span class="number">0.001</span>, gamma=<span class="number">0.3</span>)</span><br><span class="line">svdModel.train(<span class="number">100</span>, topN=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">modelpath = os.path.join(<span class="string">'logs'</span>, <span class="string">'svd'</span> + timeMarker + <span class="string">'.pkl'</span>)</span><br><span class="line"><span class="keyword">with</span> open(modelpath, <span class="string">'wb'</span>) <span class="keyword">as</span> modelfile:</span><br><span class="line">    svdModel.logger, logger = <span class="literal">None</span>, svdModel.logger  <span class="comment"># 防止日志线程读锁阻碍pickle保存模型</span></span><br><span class="line">    pickle.dump(svdModel, modelfile)</span><br><span class="line">    svdModel.logger = logger</span><br><span class="line"><span class="comment"># 读取模型</span></span><br><span class="line"><span class="comment">#del svdModel</span></span><br><span class="line"><span class="comment">#with open(modelpath, 'rb') as modelfile:</span></span><br><span class="line"><span class="comment">#    svdModel = pickle.load(modelfile)</span></span><br><span class="line"><span class="comment">#    svdModel.logger = logger</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#svd预测</span></span><br><span class="line">svdModel.evaluate(testset, topN=<span class="number">10</span>)</span><br><span class="line">winsound.Beep(<span class="number">500</span>, <span class="number">500</span>)</span><br></pre></td></tr></table></figure><h3 id="各个模块"><a href="#各个模块" class="headerlink" title="各个模块"></a>各个模块</h3><p>日志模块见 Item-based CF实践（历史博客）。</p><h4 id="数据加载模块movielens"><a href="#数据加载模块movielens" class="headerlink" title="数据加载模块movielens"></a>数据加载模块movielens</h4><p>讲解同样见Item-based CF实践。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rand</span><br><span class="line">rand.seed(<span class="number">0</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RatingData</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' movielens的rating.dat的数据集处理类 '''</span></span><br><span class="line"></span><br><span class="line">    TRAIN_SET_KEY = <span class="string">'trainset'</span></span><br><span class="line">    TEST_SET_KEY = <span class="string">'testset'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__loadFile</span><span class="params">(filepath, logger)</span>:</span></span><br><span class="line">        <span class="string">''' 加载数据文件，返回生成器。</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            filepath:数据文件的路径</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            数据文件中，每次按序返回一行数据的迭代器</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">with</span> open(filepath, <span class="string">'r'</span>, encoding=<span class="string">'UTF-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            <span class="keyword">for</span> i, line <span class="keyword">in</span> enumerate(fp):</span><br><span class="line">                <span class="keyword">yield</span> line.strip(<span class="string">'\r\n'</span>)</span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">100000</span> == <span class="number">0</span>:</span><br><span class="line">                    logger.info(<span class="string">'加载数据文件生成器 &#123;filepath&#125;(&#123;rowNum&#125;)'</span>.format(filepath=filepath, rowNum=i))</span><br><span class="line">        logger.info(<span class="string">'加载数据文件 &#123;filepath&#125; 成功'</span>.format(filepath=filepath))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getRatingDict</span><span class="params">(logger, filepath, proportion=<span class="number">0.7</span>, transport=False)</span>:</span></span><br><span class="line">        <span class="string">''' 加载评分数据字典对象，划分为训练集和测试集</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">            filepath:数据文件的路径</span></span><br><span class="line"><span class="string">            proportion:数据集训练集的划分比例，剩余的作为测试集</span></span><br><span class="line"><span class="string">            transport:是否将数据集转置，未转置是user-item，转置则是item-user</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            包含trainset和testset的字典对象</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        trainset = &#123;&#125;</span><br><span class="line">        trainsetSize = <span class="number">0</span></span><br><span class="line">        testset = &#123;&#125;</span><br><span class="line">        testsetSize = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> RatingData.__loadFile(filepath, logger):</span><br><span class="line">            <span class="comment"># 数据格式是：用户::电影::评分::时间戳</span></span><br><span class="line">            <span class="keyword">if</span> transport:</span><br><span class="line">                dimA = <span class="string">'电影'</span></span><br><span class="line">                item, user, rating, _ = line.split(<span class="string">'::'</span>)    <span class="comment"># 转置，item-user</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                dimA = <span class="string">'用户'</span></span><br><span class="line">                user, item, rating, _ = line.split(<span class="string">'::'</span>)    <span class="comment"># 不转置，user-item</span></span><br><span class="line">            user = int(user)</span><br><span class="line">            item = int(item)</span><br><span class="line">            rating = float(rating)</span><br><span class="line">            <span class="comment"># 通过比例划分数据集</span></span><br><span class="line">            <span class="keyword">if</span> rand.random() &lt; proportion:</span><br><span class="line">                trainset.setdefault(user, &#123;&#125;)</span><br><span class="line">                trainset[user][item] = rating</span><br><span class="line">                trainsetSize += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                testset.setdefault(user, &#123;&#125;)</span><br><span class="line">                testset[user][item] = rating</span><br><span class="line">                testsetSize += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">'划分训练集和测试集成功！'</span>)</span><br><span class="line">        logger.info(<span class="string">'训练集&#123;dimA&#125;数量 &#123;item&#125;'</span>.format(dimA=dimA, item = len(trainset)))</span><br><span class="line">        logger.info(<span class="string">'训练集大小 &#123;size&#125;'</span>.format(size=trainsetSize))</span><br><span class="line">        logger.info(<span class="string">'测试集&#123;dimA&#125;数量 &#123;item&#125;'</span>.format(dimA=dimA, item = len(testset)))</span><br><span class="line">        logger.info(<span class="string">'测试集大小 &#123;size&#125;'</span>.format(size=testsetSize))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;RatingData.TRAIN_SET_KEY:trainset, RatingData.TEST_SET_KEY:testset&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getSmallRatingData</span><span class="params">(logger, filepath, proportion=<span class="number">0.7</span>, ratio=<span class="number">0.3</span>, transport=False)</span>:</span></span><br><span class="line">        <span class="string">''' 加载评分数据字典对象，划分为训练集和测试集</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">            filepath:数据文件的路径</span></span><br><span class="line"><span class="string">            proportion:数据集训练集的划分比例，剩余的作为测试集</span></span><br><span class="line"><span class="string">            ratio:缩小为原数据集的比例数</span></span><br><span class="line"><span class="string">            transport:是否将数据集转置，未转置是user-item，转置则是item-user</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            包含trainset和testset的字典对象</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 获取原数据集</span></span><br><span class="line">        dataset = RatingData.getRatingDict(logger, filepath, proportion, transport)</span><br><span class="line">        trainset = dataset[RatingData.TRAIN_SET_KEY]</span><br><span class="line">        testset = dataset[RatingData.TEST_SET_KEY]</span><br><span class="line">        <span class="comment"># 获取用户集，并收缩用户集</span></span><br><span class="line">        userset = set(trainset.keys())</span><br><span class="line">        smallUserset = set()</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> userset:</span><br><span class="line">            <span class="keyword">if</span> rand.random() &lt; ratio:</span><br><span class="line">                smallUserset.add(user)</span><br><span class="line">        <span class="comment"># 获取物品集，并收缩物品集</span></span><br><span class="line">        itemset = set()</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> userset:</span><br><span class="line">            itemset |= set(trainset[user].keys())</span><br><span class="line">        ratio *= len(itemset)</span><br><span class="line">        itemset.clear()</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> smallUserset:</span><br><span class="line">            itemset |= set(trainset[user].keys())</span><br><span class="line">        ratio /= len(itemset)</span><br><span class="line">        smallItemset = set()</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> itemset:</span><br><span class="line">            <span class="keyword">if</span> rand.random() &lt; ratio:</span><br><span class="line">                smallItemset.add(item)</span><br><span class="line">        <span class="comment"># 将训练集数据，限制在缩小的用户、物品集内</span></span><br><span class="line">        smallTrainset = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> smallUserset:</span><br><span class="line">            smallTrainset[user] = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> trainset[user].keys():</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> smallItemset:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                smallTrainset[user][item] = trainset[user][item]</span><br><span class="line">        <span class="comment"># 将测试集数据，限制在缩小的用户、物品集内</span></span><br><span class="line">        smallTestset = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> smallUserset:</span><br><span class="line">            smallTestset[user] = &#123;&#125;</span><br><span class="line">            <span class="keyword">if</span> testset.get(user) == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> testset[user].keys():</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> smallItemset:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                smallTestset[user][item] = testset[user][item]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> transport:</span><br><span class="line">            dimA = <span class="string">'电影'</span></span><br><span class="line">            dimB = <span class="string">'用户'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            dimA = <span class="string">'用户'</span></span><br><span class="line">            dimB = <span class="string">'电影'</span></span><br><span class="line">        logger.info(<span class="string">'原数据集[&#123;dimA&#125;*&#123;dimB&#125;]大小：[&#123;lenA&#125;*&#123;lenB&#125;]'</span>.format(dimA=dimA,</span><br><span class="line">                    dimB=dimB, lenA=len(userset), lenB=len(itemset)))</span><br><span class="line">        logger.info(<span class="string">'收缩数据集[&#123;dimA&#125;*&#123;dimB&#125;]大小：[&#123;lenA&#125;*&#123;lenB&#125;]'</span>.format(dimA=dimA,</span><br><span class="line">                    dimB=dimB, lenA=len(smallUserset), lenB=len(smallItemset)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;RatingData.TRAIN_SET_KEY:smallTrainset, RatingData.TEST_SET_KEY:smallTestset&#125;</span><br></pre></td></tr></table></figure><h4 id="svd模块"><a href="#svd模块" class="headerlink" title="svd模块"></a>svd模块</h4><p>初始化模型的参数，用户和物品评分偏置初始化为0，用户和物品主题向量进行<script type="math/tex">[0, 0.1]</script>的随机初始化。然后，在用训练集进行数据测试，最后评估并评价。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVD</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' 基于SVD的协同过滤推荐算法 '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, logger, trainset, topicNum, lr, gamma)</span>:</span></span><br><span class="line">        <span class="string">''' 初始化函数</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">            trainset:训练集</span></span><br><span class="line"><span class="string">            topicNum:主题个数，奇异值数量</span></span><br><span class="line"><span class="string">            lr:学习率</span></span><br><span class="line"><span class="string">            gamma:正则项权重</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.logger = logger</span><br><span class="line">        self.trainset = trainset</span><br><span class="line">        self.topicNum = topicNum</span><br><span class="line">        self.lr = lr</span><br><span class="line">        self.gamma = gamma</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rate = mean + biasUser + biasItem + pUser * qItem</span></span><br><span class="line">        self.mean = <span class="number">0</span>   <span class="comment"># 所有已评分物品的均值</span></span><br><span class="line">        self.biasUser = &#123;&#125;  <span class="comment"># 用户评分偏置</span></span><br><span class="line">        self.biasItem = &#123;&#125;  <span class="comment"># 物品评分偏置</span></span><br><span class="line">        self.pUser = &#123;&#125;     <span class="comment"># 用户对topicNum个主题的偏好向量</span></span><br><span class="line">        self.qItem = &#123;&#125;     <span class="comment"># 物品在topicNum个主题的分布向量</span></span><br><span class="line"></span><br><span class="line">        self.trainMap = &#123;&#125;  <span class="comment"># 序号到(user，item)的映射，用于训练时，序号到训练样本的映射</span></span><br><span class="line"></span><br><span class="line">        self.initModel()</span><br><span class="line">        self.logger.info(<span class="string">'SVD模型建立完毕！'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initModel</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">''' 初始化模型参数：biasUser、biasItem、pUser、qItem '''</span></span><br><span class="line">        <span class="comment"># 初始化变量数组、值</span></span><br><span class="line">        itemset = set()</span><br><span class="line">        sumRate = <span class="number">0</span></span><br><span class="line">        lenRate = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> user, itemRates <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            itemset |= set(itemRates.keys())</span><br><span class="line">            sumRate += sum(itemRates.values())</span><br><span class="line">            lenRate += len(itemRates)</span><br><span class="line">            self.biasUser[user] = <span class="number">0</span></span><br><span class="line">            self.pUser[user] = np.random.rand(self.topicNum) / <span class="number">10</span></span><br><span class="line">        self.mean = sumRate/lenRate</span><br><span class="line">        self.logger.info(<span class="string">'初始化SVD，均值：&#123;mu&#125;'</span>.format(mu=self.mean))</span><br><span class="line">        self.logger.info(<span class="string">'初始化SVD，用户偏置向量为0向量'</span>)</span><br><span class="line">        self.logger.info(<span class="string">'初始化SVD，用户主题矩阵为随机矩阵'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> itemset:</span><br><span class="line">            self.biasItem[item] = <span class="number">0</span></span><br><span class="line">            self.qItem[item] = np.random.rand(self.topicNum) / <span class="number">10</span></span><br><span class="line">        self.logger.info(<span class="string">'初始化SVD，物品偏置向量为0向量'</span>)</span><br><span class="line">        self.logger.info(<span class="string">'初始化SVD，物品主题矩阵为随机矩阵'</span>)</span><br><span class="line"></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> user, itemRates <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> itemRates.keys():</span><br><span class="line">                self.trainMap[i] = (user, item)</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        self.logger.info(<span class="string">'SVD模型初始化完毕！'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, iteration, topN)</span>:</span></span><br><span class="line">        <span class="string">''' 迭代多批次训练SVD模型</span></span><br><span class="line"><span class="string">        min power(rated - rate, 2)/2 + gamma * regularization/2</span></span><br><span class="line"><span class="string">        rate = mean + biasUser + biasItem + qItem * pUser</span></span><br><span class="line"><span class="string">        regularization = power(biasUser) + power(biasItem) + power(pUser) + power(qItem)</span></span><br><span class="line"><span class="string">        故每次迭代：lr = learning rate</span></span><br><span class="line"><span class="string">        delta(biasUser) = lr * ((rate - rated) + gamma * biasUser)</span></span><br><span class="line"><span class="string">        delta(biasItem) = lr * ((rate - rated) + gamma * biasItem)</span></span><br><span class="line"><span class="string">        delta(pUser) = lr * ((rate - rated) * qItem + gamma * pUser)</span></span><br><span class="line"><span class="string">        delta(qItem) = lr * ((rate - rated) * pUser + gamma * qItem)</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            iteration:迭代次数</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.logger.info(<span class="string">'开始训练...'</span>)</span><br><span class="line">        sampleSize = len(self.trainMap)     <span class="comment"># 训练样本总数</span></span><br><span class="line">        sampleSeq = np.arange(sampleSize)    <span class="comment"># 训练样本号的训练队列</span></span><br><span class="line">        <span class="comment"># 迭代训练</span></span><br><span class="line">        self.logger.info(<span class="string">'训练前，误差为：'</span>)</span><br><span class="line">        self.evaluate(self.trainset, topN)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(iteration):</span><br><span class="line">            np.random.shuffle(sampleSeq)    <span class="comment"># 打乱训练样本号的训练队列</span></span><br><span class="line">            <span class="comment"># 取样本号，逐样本训练</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> sampleSeq:</span><br><span class="line">                user, item = self.trainMap[j]</span><br><span class="line">                rate = self.predict(user, item)     <span class="comment"># 预测得分，计算差异</span></span><br><span class="line">                rated = self.trainset[user][item]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 计算预测误差，并更新参数</span></span><br><span class="line">                rateDiff = rate - rated</span><br><span class="line">                self.biasUser[user] -= (self.lr * (rateDiff + self.gamma * self.biasUser[user]))</span><br><span class="line">                self.biasItem[item] -= (self.lr * (rateDiff + self.gamma * self.biasItem[item]))</span><br><span class="line">                self.pUser[user] -= (self.lr * (rateDiff * self.qItem[item] +</span><br><span class="line">                          self.gamma * self.pUser[user]))</span><br><span class="line">                self.qItem[item] -= (self.lr * (rateDiff * self.pUser[user] +</span><br><span class="line">                          self.gamma * self.qItem[item]))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                self.logger.info(<span class="string">'训练进度[&#123;i&#125;/&#123;iteration&#125;]，训练误差为：'</span>.format(i=i,</span><br><span class="line">                                 iteration=iteration))</span><br><span class="line">                self.evaluate(self.trainset, topN)</span><br><span class="line">                self.lr *= <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'训练后，误差为：'</span>)</span><br><span class="line">        self.evaluate(self.trainset, topN)</span><br><span class="line">        self.logger.info(<span class="string">'训练结束！'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, user, item)</span>:</span></span><br><span class="line">        <span class="string">''' 测试SVD模型</span></span><br><span class="line"><span class="string">        rate = mean + biasUser + biasItem + qItem * pUser</span></span><br><span class="line"><span class="string">        regularization = power(biasUser) + power(biasItem) + power(pUser) + power(qItem)</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            user:待预测评分的用户</span></span><br><span class="line"><span class="string">            item:待预测评分的物品</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            rate:用户user对物品item的评分</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        rate = (self.mean + self.biasUser[user] + self.biasItem[item] +</span><br><span class="line">                np.dot(self.qItem[item], self.pUser[user]))</span><br><span class="line">        <span class="keyword">return</span> rate</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(self, dataset, topN)</span>:</span></span><br><span class="line">        <span class="string">''' 评估SVD模型</span></span><br><span class="line"><span class="string">        RMSE = sqrt(mean(power(testRate - predictRate, 2)))</span></span><br><span class="line"><span class="string">        MAE = mean(abs(testRate - predictRate))</span></span><br><span class="line"><span class="string">        precision = len(I(testRate) &amp; I(topN)) / #topN</span></span><br><span class="line"><span class="string">        recall = len(I(testRate) &amp; I(topN)) / len(I(testRate))</span></span><br><span class="line"><span class="string">        recovery = len(set(topN[for all user].keys())) / len(set(testset[for all user].keys()))</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dataset:评估数据集</span></span><br><span class="line"><span class="string">            topN:top N数值</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 获取训练集的物品集</span></span><br><span class="line">        itemset = set()</span><br><span class="line">        <span class="keyword">for</span> _, itemRate <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            itemset |= itemRate.keys()</span><br><span class="line"></span><br><span class="line">        rmse = <span class="number">0</span></span><br><span class="line">        mae = <span class="number">0</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        hit = <span class="number">0</span></span><br><span class="line">        totalPredictNum = <span class="number">0</span></span><br><span class="line">        predictItemset = set()</span><br><span class="line">        testItemset = set()</span><br><span class="line">        <span class="keyword">for</span> user, itemRates <span class="keyword">in</span> dataset.items():</span><br><span class="line">            <span class="comment"># 如果该用户不在训练集内，则无法进行预测</span></span><br><span class="line">            <span class="keyword">if</span> self.biasUser.get(user) == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            testItemset |= set(itemRates.keys())</span><br><span class="line">            <span class="comment"># 对用户的物品进行预测打分</span></span><br><span class="line">            predictRate = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> itemset:</span><br><span class="line">                predictRate[item] = self.predict(user, item)</span><br><span class="line">            <span class="comment"># 以分值降序，取top N，然后转为dict变量</span></span><br><span class="line">            rateTopN = dict(sorted(predictRate.items(), key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[<span class="number">0</span>:topN])</span><br><span class="line">            <span class="keyword">if</span> np.random.rand() &gt; <span class="number">0.999</span>:</span><br><span class="line">                self.logger.info(<span class="string">'用户&#123;user&#125;的topN推荐[&#123;topN&#125;/&#123;total&#125;]是：&#123;rateTopN&#125;'</span>.format(user=user,</span><br><span class="line">                                 topN=topN, total=len(itemset), rateTopN=rateTopN))</span><br><span class="line">            predictItemset |= set(rateTopN.keys())</span><br><span class="line">            totalPredictNum += topN</span><br><span class="line">            <span class="comment"># 以测试集已评分物品为准</span></span><br><span class="line">            <span class="keyword">for</span> item, rate <span class="keyword">in</span> itemRates.items():</span><br><span class="line">                <span class="keyword">if</span> self.biasItem.get(item) == <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                rateDiff = rate - predictRate[item]</span><br><span class="line">                rmse += np.power(rateDiff, <span class="number">2</span>)</span><br><span class="line">                mae += np.abs(rateDiff)</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">in</span> rateTopN.keys():</span><br><span class="line">                    hit += <span class="number">1</span></span><br><span class="line">        rmse = np.sqrt(rmse / count)</span><br><span class="line">        mae /= count</span><br><span class="line">        precision = hit / totalPredictNum</span><br><span class="line">        recall = hit / count</span><br><span class="line">        recovery = len(predictItemset) / len(testItemset)</span><br><span class="line">        self.logger.info(<span class="string">'本次评估RMSE：&#123;rmse&#125;'</span>.format(rmse=rmse))</span><br><span class="line">        self.logger.info(<span class="string">'本次评估mae：&#123;mae&#125;'</span>.format(mae=mae))</span><br><span class="line">        self.logger.info(<span class="string">'本次评估预测准确度：&#123;precision&#125;'</span>.format(precision=precision))</span><br><span class="line">        self.logger.info(<span class="string">'本次评估召回率：&#123;recall&#125;'</span>.format(recall=recall))</span><br><span class="line">        self.logger.info(<span class="string">'本次评估覆盖率：&#123;recovery&#125;'</span>.format(recovery=recovery))</span><br></pre></td></tr></table></figure><p>思考的点包括：</p><ol><li>训练过程涉及到超参的调节：迭代次数、学习步长、罚项的权重；其中，学习步长还涉及到随着迭代步长的变化规则。</li><li>评价标准的选取。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个实现层面上倒是比较好实现，但在评估时却发现了一个有趣的事：<strong>随着训练迭代递增，RMSE下降，而Top N推荐的准确率也跟着下降了。是的，预测更加准确，但top N推荐效果却下降了</strong>。</p><p>其实这个事情，在Greg Linden的09年3月份博客里就已经思考过了（Greg Linden是Amazon早期推荐系统的主要贡献者之一），在衡量好的推荐算法上，RMSE低并不是说Top N预测效果（Recall@n，Precision@n）就好。在5星评分里，本来用户评4星，你预测3星，和评3新预测2星，效果和意义上都更差了，因为对于差的物品，用户并不care，唯一matter的是，他们喜欢的、高分的玩意。并且在网络世界里，用户的评分受各种因素的影响（如视频流畅度、物品的完整性），他们更trust的，还是能给出推荐理由的算法（Amazon在这方面走得更远一些）。并且，推荐的多样性、新颖度、可解释性等，都对算法十分有益。所以说，RMSE评价也不能全仰仗。更多可参考的论文还有，Performance of recommender algorithms on top-n recommendation tasks。</p><p>到现实中，可能某部电影口评差，但还有许多人想看（看个热闹，好批斗一番？或者，为了扩充自己观影资料库里的多样性？）。所以，在评价指标上，莫慌。理解算法原理，明确业务指标，理清推荐目的，可也是很重要的实战指导意义。</p><p>个人偏好，注重的更多的还是，对算法的后续分析、可视化、原理深入探索，还有运营数据的理解及对当前系统所使用的算法的反馈意义。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 协同过滤 </tag>
            
            <tag> 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于物品的协同过滤</title>
      <link href="/2018/07/16/1_%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movielens-1m/"/>
      <url>/2018/07/16/1_%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4_movielens-1m/</url>
      
        <content type="html"><![CDATA[<p align="center">对<strong>基于物品的协同过滤</strong>理解和复现的一点记录。</p><a id="more"></a><h3 id="程序入口"><a href="#程序入口" class="headerlink" title="程序入口"></a>程序入口</h3><ul><li>日志对象；</li><li>读取数据/分割数据集；</li><li>创建推荐算法对象/初始化参数；</li><li>计算相似度矩阵；</li><li>预测评分并推荐；</li><li>评价指标计算。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> logger <span class="keyword">import</span> Logger</span><br><span class="line"><span class="keyword">from</span> movielens <span class="keyword">import</span> RatingData</span><br><span class="line"><span class="keyword">from</span> cf <span class="keyword">import</span> CF</span><br><span class="line"><span class="keyword">from</span> similarity <span class="keyword">import</span> Similarity</span><br><span class="line"></span><br><span class="line"><span class="string">''' 基于kNN-CF推荐算法的流程 '''</span></span><br><span class="line"><span class="comment"># 日志打印对象</span></span><br><span class="line">logPath = os.path.join(<span class="string">'logs'</span>, <span class="string">'kNNCF.log'</span>)</span><br><span class="line">logger = Logger.getLogger(logPath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">ratingfile = os.path.join(<span class="string">'ml-1m'</span>, <span class="string">'ratings.dat'</span>)</span><br><span class="line">proportion = <span class="number">0.7</span>        <span class="comment"># 训练集占总数据集比例，其余为测试集</span></span><br><span class="line"><span class="comment"># 基于item</span></span><br><span class="line">itemRatingDict = RatingData.getItemRatingDict(logger, ratingfile, proportion)</span><br><span class="line">itemTrainset = itemRatingDict[RatingData.TRAIN_SET_KEY]</span><br><span class="line">itemTestset = itemRatingDict[RatingData.TEST_SET_KEY]</span><br><span class="line"><span class="comment"># 计算相似度矩阵，并推荐</span></span><br><span class="line">cfAlgo = CF(logger, itemTrainset, itemTestset, neighborK=<span class="number">20</span>, topN=<span class="number">10</span>)</span><br><span class="line">cfAlgo.calcSimMat(Similarity.rateDiffDivCoRated)</span><br><span class="line">cfAlgo.recommand()</span><br><span class="line"><span class="comment"># 评价</span></span><br><span class="line">cfAlgo.evaluate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 播放完成音乐</span></span><br><span class="line"><span class="comment">#from playsound import playsound</span></span><br><span class="line"><span class="comment">#playsound('C:/Users/Public/Music/Sample Music/Sleep Away.mp3') # 无法设置播放时间</span></span><br><span class="line"><span class="keyword">import</span> winsound</span><br><span class="line">winsound.Beep(<span class="number">500</span>, <span class="number">500</span>) <span class="comment"># 不好听</span></span><br></pre></td></tr></table></figure><h3 id="各个模块"><a href="#各个模块" class="headerlink" title="各个模块"></a>各个模块</h3><h4 id="日志模块-logger-py"><a href="#日志模块-logger-py" class="headerlink" title="日志模块 logger.py"></a>日志模块 logger.py</h4><p>打印到控制台，同时也可以记录到 logPath 路径下的文件中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logger</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' 日志记录类，记录到目录路径文件内，同时也打印到console上 '''</span></span><br><span class="line">    __logger = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__initLogger</span><span class="params">(logPath, logLevel)</span>:</span></span><br><span class="line">        <span class="string">''' 创建日志对象，并放入到__logger字典。key为logPath，value为logger对象</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logPath:日志文件路径</span></span><br><span class="line"><span class="string">            logLevel:日志打印水平</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 设置日志记录等级、格式、文件</span></span><br><span class="line">        logger = logging.getLogger(logPath)</span><br><span class="line">        logger.setLevel(logLevel)</span><br><span class="line">        <span class="comment"># Formatter - 格式</span></span><br><span class="line">        formatter = logging.Formatter(<span class="string">r'%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Console - 控制台就打印debug</span></span><br><span class="line">        consoleHandler = logging.StreamHandler()</span><br><span class="line">        consoleHandler.setLevel(logLevel)</span><br><span class="line">        consoleHandler.setFormatter(formatter)</span><br><span class="line">        <span class="comment"># 文件 - 文件就记录error</span></span><br><span class="line">        fileHandler = logging.FileHandler(logPath, mode=<span class="string">'w'</span>, encoding=<span class="string">'UTF-8'</span>)</span><br><span class="line">        fileHandler.setLevel(logLevel)</span><br><span class="line">        fileHandler.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 添加句柄</span></span><br><span class="line">        logger.addHandler(consoleHandler)</span><br><span class="line">        logger.addHandler(fileHandler)</span><br><span class="line">        logger.info(<span class="string">'创建日志文件&#123;logfile&#125;成功！'</span>.format(logfile=logPath))</span><br><span class="line">        Logger.__logger[logPath] = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLogger</span><span class="params">(logPath, logLevel=logging.DEBUG)</span>:</span></span><br><span class="line">        <span class="string">''' 从__logger字典获取日志对象，key为logPath。若logger对象不存在，则新建</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logPath:日志文件路径</span></span><br><span class="line"><span class="string">            logLevel:日志打印水平，默认打印debug等级及以上</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            logger日志打印对象</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">if</span> Logger.__logger.get(logPath) == <span class="literal">None</span>:</span><br><span class="line">            Logger.__initLogger(logPath, logLevel)</span><br><span class="line">        <span class="keyword">return</span> Logger.__logger.get(logPath)</span><br></pre></td></tr></table></figure><p><strong>Question</strong>：如果出现日志打印多次的情况（logger.info(‘1’)但是打印了两次1），是因为程序异常停止，导致自己创建的logger对象会被回收，但是logging.getLogger创建的对象依然存在，若此时再次创建重名的logging.getLogger对象，则会重复添加打印通道的句柄，导致多处打印（因为logging.getLogger(name)是对name的单例模式）。</p><p><strong>解决</strong>：出现异常了，给换个名字创建日志对象，或者，quit()重启console就行，或者，运行下面语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> imp <span class="keyword">import</span> reload</span><br><span class="line">reload(logging)</span><br></pre></td></tr></table></figure><h4 id="数据加载模块-movielens-py"><a href="#数据加载模块-movielens-py" class="headerlink" title="数据加载模块 movielens.py"></a>数据加载模块 movielens.py</h4><p>用字典变量存储，类似<code>ratesDict[item][user] = rate</code>。然后按设定比例、随机种子，分割训练集和测试集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rand</span><br><span class="line">rand.seed(<span class="number">0</span>)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RatingData</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' movielens的rating.dat的数据集处理类 '''</span></span><br><span class="line"></span><br><span class="line">    TRAIN_SET_KEY = <span class="string">'trainset'</span></span><br><span class="line">    TEST_SET_KEY = <span class="string">'testset'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__loadFile</span><span class="params">(filepath, logger)</span>:</span></span><br><span class="line">        <span class="string">''' 加载数据文件，返回生成器。</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            filepath:数据文件的路径</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            数据文件中，每次按序返回一行数据的迭代器</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">with</span> open(filepath, <span class="string">'r'</span>, encoding=<span class="string">'UTF-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            <span class="keyword">for</span> i, line <span class="keyword">in</span> enumerate(fp):</span><br><span class="line">                <span class="keyword">yield</span> line.strip(<span class="string">'\r\n'</span>)</span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">100000</span> == <span class="number">0</span>:</span><br><span class="line">                    logger.info(<span class="string">'加载数据文件生成器 &#123;filepath&#125;(&#123;rowNum&#125;)'</span>.format(filepath=filepath, rowNum=i))</span><br><span class="line">        logger.info(<span class="string">'加载数据文件 &#123;filepath&#125; 成功'</span>.format(filepath=filepath))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getItemRatingDict</span><span class="params">(logger, filepath, proportion)</span>:</span></span><br><span class="line">        <span class="string">''' 加载评分数据字典对象，划分为训练集和测试集</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            logger:日志记录对象</span></span><br><span class="line"><span class="string">            filepath:数据文件的路径</span></span><br><span class="line"><span class="string">            proportion:数据集训练集的划分比例，剩余的作为测试集</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            包含trainset和testset的字典对象</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        trainset = &#123;&#125;</span><br><span class="line">        trainsetSize = <span class="number">0</span></span><br><span class="line">        testset = &#123;&#125;</span><br><span class="line">        testsetSize = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> RatingData.__loadFile(filepath, logger):</span><br><span class="line">            user, item, rating, _ = line.split(<span class="string">'::'</span>)    <span class="comment"># 数据格式是：用户::电影::评分::时间戳</span></span><br><span class="line">            user = int(user)</span><br><span class="line">            item = int(item)</span><br><span class="line">            rating = float(rating)</span><br><span class="line">            <span class="comment"># 通过比例划分数据集</span></span><br><span class="line">            <span class="keyword">if</span> rand.random() &lt; proportion:</span><br><span class="line">                trainset.setdefault(item, &#123;&#125;)</span><br><span class="line">                trainset[item][user] = rating</span><br><span class="line">                trainsetSize += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                testset.setdefault(item, &#123;&#125;)</span><br><span class="line">                testset[item][user] = rating</span><br><span class="line">                testsetSize += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">'划分训练集和测试集成功！'</span>)</span><br><span class="line">        logger.info(<span class="string">'训练集物品数量 &#123;item&#125;'</span>.format(item = len(trainset)))</span><br><span class="line">        logger.info(<span class="string">'训练集大小 &#123;size&#125;'</span>.format(size=trainsetSize))</span><br><span class="line">        logger.info(<span class="string">'测试集物品数量 &#123;item&#125;'</span>.format(item = len(testset)))</span><br><span class="line">        logger.info(<span class="string">'测试集大小 &#123;size&#125;'</span>.format(size=testsetSize))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;RatingData.TRAIN_SET_KEY:trainset, RatingData.TEST_SET_KEY:testset&#125;</span><br></pre></td></tr></table></figure><p>一个良好的实践就是：总是<strong>先用较小的数据集</strong>测试功能、性能；针对到movielens 1m数据集，原来大概是<code>3000+ item * 6000+ user</code>，相似度计算就大概<code>O(3000 * 3000 * 6000)</code>时间复杂度；把数据集缩小为 1000item * 2000 user，时间复杂度可是蹭蹭蹭的降下来了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSmallRatingData</span><span class="params">(logger, filepath, proportion=<span class="number">0.7</span>, ratio=<span class="number">0.3</span>, transport=False)</span>:</span></span><br><span class="line">    <span class="string">''' 加载评分数据字典对象，划分为训练集和测试集</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        logger:日志记录对象</span></span><br><span class="line"><span class="string">        filepath:数据文件的路径</span></span><br><span class="line"><span class="string">        proportion:数据集训练集的划分比例，剩余的作为测试集</span></span><br><span class="line"><span class="string">        ratio:缩小为原数据集的比例数</span></span><br><span class="line"><span class="string">        transport:是否将数据集转置，未转置是user-item，转置则是item-user</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        包含trainset和testset的字典对象</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 获取原数据集</span></span><br><span class="line">    dataset = RatingData.getRatingDict(logger, filepath, proportion, transport)</span><br><span class="line">    trainset = dataset[RatingData.TRAIN_SET_KEY]</span><br><span class="line">    testset = dataset[RatingData.TEST_SET_KEY]</span><br><span class="line">    <span class="comment"># 获取用户集、物品集</span></span><br><span class="line">    userset = set(trainset.keys())</span><br><span class="line">    itemset = set()</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> userset:</span><br><span class="line">        itemset |= set(trainset[user].keys())</span><br><span class="line">    <span class="comment"># 缩小用户集、物品集</span></span><br><span class="line">    smallUserset = set()</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> userset:</span><br><span class="line">        <span class="keyword">if</span> rand.random() &lt; ratio:</span><br><span class="line">            smallUserset.add(user)</span><br><span class="line">    smallItemset = set()</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> itemset:</span><br><span class="line">        <span class="keyword">if</span> rand.random() &lt; ratio:</span><br><span class="line">            smallItemset.add(item)</span><br><span class="line">    <span class="comment"># 将训练集数据，限制在缩小的用户、物品集内</span></span><br><span class="line">    smallTrainset = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> smallUserset:</span><br><span class="line">        smallTrainset[user] = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> trainset[user].keys():</span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> smallItemset:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            smallTrainset[user][item] = trainset[user][item]</span><br><span class="line">    <span class="comment"># 将测试集数据，限制在缩小的用户、物品集内</span></span><br><span class="line">    smallTestset = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> smallUserset:</span><br><span class="line">        smallTestset[user] = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> testset[user].keys():</span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> smallItemset:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            smallTestset[user][item] = testset[user][item]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transport:</span><br><span class="line">        dimA = <span class="string">'电影'</span></span><br><span class="line">        dimB = <span class="string">'用户'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dimA = <span class="string">'用户'</span></span><br><span class="line">        dimB = <span class="string">'电影'</span></span><br><span class="line">    logger.info(<span class="string">'原数据集[&#123;dimA&#125;*&#123;dimB&#125;]大小：[&#123;lenA&#125;*&#123;lenB&#125;]'</span>.format(dimA=dimA,</span><br><span class="line">                dimB=dimB, lenA=len(userset), lenB=len(itemset)))</span><br><span class="line">    logger.info(<span class="string">'收缩数据集[&#123;dimA&#125;*&#123;dimB&#125;]大小：[&#123;lenA&#125;*&#123;lenB&#125;]'</span>.format(dimA=dimA,</span><br><span class="line">                dimB=dimB, lenA=len(smallUserset), lenB=len(smallItemset)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;RatingData.TRAIN_SET_KEY:smallTrainset, RatingData.TEST_SET_KEY:smallTestset&#125;</span><br></pre></td></tr></table></figure><h4 id="相似度函数模块-similarity-py"><a href="#相似度函数模块-similarity-py" class="headerlink" title="相似度函数模块 similarity.py"></a>相似度函数模块 similarity.py</h4><p>提供相似度计算的函数，这里写了3个相似度度量函数：共现、LiRa、自己推的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Similarity</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' 相似度计算工具类 '''</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">coOccurSim</span><span class="params">(a, b)</span>:</span></span><br><span class="line">        <span class="string">''' 向量a,b的共现相似度，有点类似于关联分析</span></span><br><span class="line"><span class="string">        sim = count(a and b) / sqrt(count(a) * count(b))</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 取评分用户的交集</span></span><br><span class="line">        setA = set(a.keys())</span><br><span class="line">        setB = set(b.keys())</span><br><span class="line">        users = setA &amp; setB</span><br><span class="line">        coOccur = len(users)</span><br><span class="line">        <span class="comment"># 若物品没有评分用户交集，则说明没有相似性</span></span><br><span class="line">        <span class="keyword">if</span> coOccur == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 统计评分共现项</span></span><br><span class="line">        occurA = len(setA)</span><br><span class="line">        occurB = len(setB)</span><br><span class="line">        <span class="comment"># 计算共现相似度</span></span><br><span class="line">        sim = coOccur / np.sqrt(occurA * occurB)</span><br><span class="line">        <span class="keyword">return</span> sim</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">liRa</span><span class="params">(a, b)</span>:</span></span><br><span class="line">        <span class="string">''' LiRa评分</span></span><br><span class="line"><span class="string">        sim = log_10(p1/p2)</span></span><br><span class="line"><span class="string">        p1 = cum(power(1/2, dist+1))</span></span><br><span class="line"><span class="string">        p2 = cum(p(coOccur))</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 取评分用户的交集</span></span><br><span class="line">        users = set(a.keys()) &amp; set(b.keys())</span><br><span class="line">        <span class="comment"># 若物品没有评分用户交集，则说明没有相似性</span></span><br><span class="line">        <span class="keyword">if</span> len(users) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        p1 = <span class="number">1</span></span><br><span class="line">        p2 = <span class="number">1</span></span><br><span class="line">        sim = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> users:</span><br><span class="line">            <span class="keyword">if</span> np.abs(a[user] - b[user]) == <span class="number">4</span>:</span><br><span class="line">                p1 = np.power(<span class="number">1</span>/<span class="number">2</span>, np.abs(a[user] - b[user]))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p1 = np.power(<span class="number">1</span>/<span class="number">2</span>, np.abs(a[user] - b[user]) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> np.abs(a[user] - b[user]) == <span class="number">0</span>:</span><br><span class="line">                p2 = <span class="number">1</span>/<span class="number">5</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p2 = <span class="number">2</span> * (<span class="number">5</span> - np.abs(a[user] - b[user])) / <span class="number">25</span></span><br><span class="line"></span><br><span class="line">            sim += np.log10(p1/p2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rateDiffDivCoRated</span><span class="params">(a, b)</span>:</span></span><br><span class="line">        <span class="string">''' 相似性 ~ 评分差异性/共同评分项概率</span></span><br><span class="line"><span class="string">        sim</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 取评分用户的交集</span></span><br><span class="line">        setA = set(a.keys())</span><br><span class="line">        setB = set(b.keys())</span><br><span class="line">        users = setA &amp; setB</span><br><span class="line"></span><br><span class="line">        coOccur = len(users)</span><br><span class="line">        <span class="comment"># 若物品没有评分用户交集，则说明没有相似性</span></span><br><span class="line">        <span class="keyword">if</span> coOccur &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        lenA = len(setA)</span><br><span class="line">        lenB = len(setB)</span><br><span class="line">        sim = <span class="number">0</span></span><br><span class="line">        warnings.filterwarnings(<span class="string">'error'</span>)</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> users:</span><br><span class="line">            rateDiff = np.abs(a[user] - b[user])</span><br><span class="line">            sim += (<span class="number">1</span> - rateDiff/<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        sim /= np.sqrt(lenA * lenB)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sim</span><br></pre></td></tr></table></figure><p><strong>Question</strong>. 为什么不用 pearson或者cosine等等其他的？</p><p>事实上，我试过了，效果没共现好（LiRa&lt;共现&lt;推导的）。</p><p>由于稀疏性，导致某些物品的co-rated用户非常少，那此时计算出来的similarity的可信度就值得推敲了，这是一些相似度计算方法，必须面对的一个问题。一种方式是设定个co-rated阈值<script type="math/tex">x_{threh}</script>控制similarity可信度：</p><script type="math/tex; mode=display">\alpha(x_{co-rated}) = \left\{\begin{matrix}\frac{x_{co-rated}}{x_{threh}} & if\; x_{co-rated} < x_{threh}\\1 & otherwise\end{matrix}\right.</script><p>共现则不存在这样的问题，因为它本身相似度就与co-rated数成正比（2010 Google在youtube视频推荐算法用的相似度度量[The YouTube video recommendation system]）。LiRa是我找到的2017年的针对这个问题的论文提出的方法，实测效果没共现好。不过想法倒是挺好：在共现的想法上，加入概率和对评分差异的考虑。</p><p>然后我就沿着这个思路，推导一波，简化一波，得出了rateDiffDivCoRated函数的公式，效果好像和共现的差不多（或者好一点），不过有个超参需要设置。这是个值得思考的点。</p><h4 id="基于物品的协同过滤-cf-py"><a href="#基于物品的协同过滤-cf-py" class="headerlink" title="基于物品的协同过滤 cf.py"></a>基于物品的协同过滤 cf.py</h4><p>包含4个函数：</p><ul><li>初始化；</li><li>相似度矩阵计算；</li><li>推荐（kNN相似item选取 + 预测评分计算 + Top-N item选取）；</li><li>评估（准确率、召回率、覆盖率）。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CF</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">''' TopN推荐 - 协同过滤(Collaborative Filtering) '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, logger, trainset, testset, neighborK=<span class="number">20</span>, topN=<span class="number">10</span>)</span>:</span></span><br><span class="line">        self.logger = logger    <span class="comment"># 日志对象</span></span><br><span class="line">        self.trainset = trainset    <span class="comment"># 训练集</span></span><br><span class="line">        self.testset = testset      <span class="comment"># 测试集</span></span><br><span class="line">        self.neighborK = neighborK      <span class="comment"># 近邻数</span></span><br><span class="line">        self.topN = topN    <span class="comment"># 推荐数</span></span><br><span class="line">        self.simArray = &#123;&#125;      <span class="comment"># 物品相似度矩阵</span></span><br><span class="line">        self.predictRates = &#123;&#125;</span><br><span class="line">        <span class="comment"># 用于推荐算法的评价</span></span><br><span class="line">        self.precision = <span class="number">0</span></span><br><span class="line">        self.recall = <span class="number">0</span></span><br><span class="line">        self.coverage = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'相似近邻物品数量 = &#123;kNNValue&#125;'</span>.format(kNNValue=self.neighborK))</span><br><span class="line">        self.logger.info(<span class="string">'推荐top N物品数量 = &#123;topNValue&#125;'</span>.format(topNValue=self.topN))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calcSimMat</span><span class="params">(self, simFunc)</span>:</span></span><br><span class="line">        <span class="string">''' 计算物品相似度矩阵 '''</span></span><br><span class="line">        self.logger.info(<span class="string">'计算物品相似度矩阵...'</span>)</span><br><span class="line">        totalItemNum = len(self.trainset.keys())</span><br><span class="line">        itemNum = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> itemA, userRatesA <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            <span class="keyword">for</span> itemB, userARatesB <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">                <span class="keyword">if</span> itemA == itemB:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 若对角相似度已经存在，则直接复制</span></span><br><span class="line">                self.simArray.setdefault(itemA, &#123;&#125;)</span><br><span class="line">                <span class="keyword">if</span> self.simArray.get(itemB) != <span class="literal">None</span> <span class="keyword">and</span> self.simArray[itemB].get(itemA) != <span class="literal">None</span>:</span><br><span class="line">                    self.simArray[itemA][itemB] = self.simArray[itemB][itemA]</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                self.simArray[itemA][itemB] = simFunc(userRatesA, userARatesB)</span><br><span class="line">            <span class="comment"># 记录迭代次数日志</span></span><br><span class="line">            itemNum += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> itemNum % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                self.logger.info(<span class="string">'计算相似度矩阵进度：&#123;rowNum&#125;/&#123;totalNum&#125;'</span>.format(rowNum=itemNum, totalNum=totalItemNum))</span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'计算物品相似度矩阵成功！'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">recommand</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">''' 根据近邻数K，推荐Top N '''</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 给物品相似度排序</span></span><br><span class="line">        <span class="keyword">for</span> item, itemSim <span class="keyword">in</span> self.simArray.items():</span><br><span class="line">            <span class="comment"># 产生由前K个相似的物品(item, sim)组成的列表</span></span><br><span class="line">            self.simArray[item] = sorted(itemSim.items(), key=itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)[:self.neighborK]</span><br><span class="line">            <span class="keyword">if</span> random.random() &gt; <span class="number">0.99</span>:</span><br><span class="line">                self.logger.info(<span class="string">'example:物品[&#123;item&#125;]的相似近邻K物品为：&#123;items&#125;'</span>.format(item=item, items=self.simArray[item]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取用户集合</span></span><br><span class="line">        users = set()</span><br><span class="line">        <span class="keyword">for</span> _, userRates <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            users |= set(userRates.keys())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对每个用户的每个物品，由最相似的K个物品预测评分</span></span><br><span class="line">        self.predictRates = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> users:</span><br><span class="line">            self.predictRates.setdefault(user, &#123;&#125;)</span><br><span class="line">            <span class="keyword">for</span> item, itemSims <span class="keyword">in</span> self.simArray.items():</span><br><span class="line">                <span class="comment"># 若用户已对该物品X评分，则不用进行预测</span></span><br><span class="line">                <span class="keyword">if</span> self.trainset[item].get(user) != <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                sumSim = <span class="number">0</span></span><br><span class="line">                sumPredictRate = <span class="number">0</span></span><br><span class="line">                coRatedNum = <span class="number">0</span></span><br><span class="line">                <span class="comment"># 遍历预测物品X的相似物品k</span></span><br><span class="line">                <span class="keyword">for</span> itemInSim, sim <span class="keyword">in</span> itemSims:</span><br><span class="line">                    <span class="comment"># 若用户没对相似物品k评分，则该物品k提供不了预测</span></span><br><span class="line">                    <span class="keyword">if</span> self.trainset[itemInSim].get(user) == <span class="literal">None</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                    sumPredictRate += (self.trainset[itemInSim][user] * sim)</span><br><span class="line">                    sumSim += sim</span><br><span class="line">                    coRatedNum += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 标准化</span></span><br><span class="line">                <span class="keyword">if</span> sumSim != <span class="number">0</span>:</span><br><span class="line">                    self.predictRates[user][item] =  sumPredictRate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保留预测评分中的top N</span></span><br><span class="line">        <span class="keyword">for</span> user, itemRates <span class="keyword">in</span> self.predictRates.items():</span><br><span class="line">            <span class="keyword">if</span> len(itemRates) &lt;= self.topN:</span><br><span class="line">                self.predictRates[user] = sorted(itemRates.items(), key=itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.predictRates[user] = sorted(itemRates.items(), key=itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)[:self.topN]</span><br><span class="line">            <span class="keyword">if</span> random.random() &gt; <span class="number">0.99</span>:</span><br><span class="line">                self.logger.info(<span class="string">'example:用户[&#123;u&#125;]的top N物品为：&#123;i&#125;'</span>.format(u=user, i=self.predictRates[user]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 将以user-item的预测评分，转换为item-user评分</span></span><br><span class="line">        predictItemNum = <span class="number">0</span></span><br><span class="line">        predictItemRates = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> user, itemRates <span class="keyword">in</span> self.predictRates.items():</span><br><span class="line">            predictItemNum += len(itemRates)</span><br><span class="line">            <span class="keyword">for</span> item, rate <span class="keyword">in</span> itemRates:</span><br><span class="line">                predictItemRates.setdefault(item, &#123;&#125;)</span><br><span class="line">                predictItemRates[item][user] = rate</span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'总预测物品数为：&#123;num&#125;'</span>.format(num=predictItemNum))</span><br><span class="line">        <span class="comment"># 将测试集与预测集进行比较评价：覆盖率、准确度、召回率、预测误差</span></span><br><span class="line">        predictItemTypeNum = len(predictItemRates.keys())</span><br><span class="line">        itemTypeNum = len(self.testset.keys())</span><br><span class="line">        self.coverage = predictItemTypeNum/itemTypeNum    <span class="comment"># 预测覆盖率 = 预测物品种类 / 总物品种类</span></span><br><span class="line">        self.logger.info(<span class="string">'总预测物品种类/总物品种类为：&#123;cov&#125;=&#123;pred&#125;/&#123;total&#125;'</span>.format(cov=self.coverage,</span><br><span class="line">                         pred=predictItemTypeNum, total=itemTypeNum))</span><br><span class="line"></span><br><span class="line">        hit = <span class="number">0</span></span><br><span class="line">        rateNum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> item, userRates <span class="keyword">in</span> self.testset.items():</span><br><span class="line">            rateNum += len(userRates.keys())</span><br><span class="line">            <span class="keyword">for</span> user, rate <span class="keyword">in</span> userRates.items():</span><br><span class="line">                <span class="keyword">if</span> predictItemRates.get(item) == <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> predictItemRates[item].get(user) != <span class="literal">None</span>:</span><br><span class="line">                    hit += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.precision = hit/predictItemNum   <span class="comment"># 预测准确度 = 预测中 / 总预测物品数</span></span><br><span class="line">        self.recall = hit/rateNum    <span class="comment"># 预测召回率 = 预测中 / 测试集用户评分数</span></span><br><span class="line"></span><br><span class="line">        self.logger.info(<span class="string">'预测准确度 &#123;precision&#125;'</span>.format(precision=self.precision))</span><br><span class="line">        self.logger.info(<span class="string">'预测召回率 &#123;recall&#125;'</span>.format(recall=self.recall))</span><br><span class="line">        self.logger.info(<span class="string">'预测覆盖率 &#123;coverage&#125;'</span>.format(coverage=self.coverage))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 随机预测的准确率 = N * 测试集用户评分总数 / （物品种类数 * 用户数 - 已评分过的物品数）</span></span><br><span class="line">        totalRateNum = itemTypeNum * len(self.predictRates)</span><br><span class="line">        ratedNum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> item, userRates <span class="keyword">in</span> self.trainset.items():</span><br><span class="line">            ratedNum += len(userRates)</span><br><span class="line">        unrateNum = totalRateNum - ratedNum</span><br><span class="line">        randomPrecision = self.topN * rateNum/unrateNum</span><br><span class="line">        self.logger.info(<span class="string">'随机预测误差 &#123;randomPrecision&#125;'</span>.format(randomPrecision=randomPrecision))</span><br></pre></td></tr></table></figure><p><strong>Question</strong>：预测评分</p><p>是的，又是一个值得思考的点。用已评分物品来预测未评分物品，需要考量：该用户已评分物品数据多不？与未评分物品的相似性够不？足够支撑预测不？如何计算预测评分（用相似度加权平均？那明明低相似度的物品不应该比高相似度的物品更能预测评分，为什么还同样权重加权平均？）</p><p>我这里针对任一用户，待预测物品基于其已评分物品集合进行加权累加<script type="math/tex">\sum(rated * sim)</script>，粗暴的利用用户偏好进行推荐（用户偏好的某一类别物品，那么该类别内的物品的物品相似度高、已评分物品数多，则预测分数高），容易造成推荐类别单一。</p><p>故是否可以先对物品进行分类，然后对每类推荐物品数设置一个阈值或罚项，以权衡多样性和用户偏好？</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>实战的话：</p><ol><li>先用小数据集，快速调试算法功能、性能，甚至初步调参；</li><li>在前期测试阶段，对于公式计算的模块，使用warnings.filterwarnings(‘error’)，将warning也可作为exception进行捕捉，这样可以打印公式计算过程中warning的信息。后期解决问题了，便可以移除。</li></ol><p>理论的话，需要思考：</p><ol><li>co-rated数量对相似度计算的影响；</li><li>已评分数和相似度大小对评分预测的影响。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 协同过滤 </tag>
            
            <tag> 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
